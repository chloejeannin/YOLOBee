{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloejeannin/YOLOBee/blob/main/notebook/beesdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction:\n",
        "This program will train a neural network to recognize bees on videos or pictures.\n"
      ],
      "metadata": {
        "id": "BXW5_RP9I40n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First connect to google drive and clone the YOLOBee repositary"
      ],
      "metadata": {
        "id": "oQP9-I6f3HiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "CAbBPQVjuhg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFEmFd881JmB",
        "outputId": "62569384-4d42-4f92-bd32-6b27fd738cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q1VyVG3grEW",
        "outputId": "e4951476-2ee0-4751-878c-ccb3519a66f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOBee'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 304 (delta 88), reused 16 (delta 16), pack-reused 137\u001b[K\n",
            "Receiving objects: 100% (304/304), 74.68 MiB | 45.17 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chloejeannin/YOLOBee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEWzJcuXHuOc",
        "outputId": "29b3efa3-a220-4bd5-960f-2c19a867fe57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOBee/Yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd YOLOBee/Yolov5/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.unpack_archive(\"frames_04+frames_2.zip\")"
      ],
      "metadata": {
        "id": "1XDATk8vexcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0vbqOeTFo-7"
      },
      "source": [
        "Augmentation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The augmentation can allow the algorithm to train on more data that it has. It will create pictures, based on the image of your dataset. The images will be  transformed by different ways. In this case, they will undergo 6 modifications, an Horizontal and vertical Flip, an RandomSizedBBoxSafeCrop, they will be Transpose, Rotate90 and ShiftScaleRotate."
      ],
      "metadata": {
        "id": "quEOuYzI3wUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BftPVP1bkHHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9468510-7098-4330-e8bc-d44c6054c651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SciAugment'...\n",
            "remote: Enumerating objects: 295, done.\u001b[K\n",
            "remote: Counting objects: 100% (238/238), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 295 (delta 112), reused 137 (delta 64), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (295/295), 1.32 MiB | 20.49 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/martinschatz-cz/SciAugment.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "875dyFkrkKSf",
        "outputId": "41a58ba5-819e-4ddd-f005-2613347a0a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting albumentations==1.4.8 (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading albumentations-1.4.8-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m371.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless>=3.4.18.65 in /usr/local/lib/python3.10/dist-packages (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 2)) (4.10.0.84)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 4)) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (1.11.4)\n",
            "Collecting scikit-image>=0.21.0 (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (4.12.2)\n",
            "Collecting scikit-learn>=1.3.2 (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2.8.0)\n",
            "Collecting albucore>=0.0.4 (from albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading albucore-0.0.12-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.4->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2.20.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (3.3)\n",
            "Collecting imageio (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3))\n",
            "  Downloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2024.6.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.8->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (2.8.2)\n",
            "Installing collected packages: imageio, scikit-learn, scikit-image, albucore, albumentations\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Removing file or directory /usr/local/bin/imageio_download_bin\n",
            "      Removing file or directory /usr/local/bin/imageio_remove_bin\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/imageio-2.31.6.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/imageio/\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "  changing mode of /usr/local/bin/imageio_download_bin to 755\n",
            "  changing mode of /usr/local/bin/imageio_remove_bin to 755\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_learn-1.2.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_learn.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/sklearn/\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Removing file or directory /usr/local/bin/skivi\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/doc/ext/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_image-0.19.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_image.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/skimage/\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.3.1\n",
            "    Uninstalling albumentations-1.3.1:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/albumentations-1.3.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/albumentations/\n",
            "      Successfully uninstalled albumentations-1.3.1\n",
            "Successfully installed albucore-0.0.12 albumentations-1.4.8 imageio-2.34.2 scikit-image-0.24.0 scikit-learn-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lTp8RI39YosQ"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# SciAug_tools\n",
        "import copy\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from shutil import rmtree\n",
        "from sys import stdout\n",
        "from xml.dom import minidom\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "\n",
        "class SciAugment:\n",
        "    version = \"0.2.0\"\n",
        "    source = \"https://github.com/martinschatz-cz/SciAugment\"\n",
        "    author = \"Martin Schätz\"\n",
        "    aug_type = \"\"\n",
        "    augment = []\n",
        "    channel_augment = []\n",
        "    aug_dict = {\n",
        "        -1: \"no augmentation\",\n",
        "        0: \"HorizontalFlip(p=1)\",\n",
        "        1: \"RandomBrightnessContrast(contrast_limit=0.2,p=1)\",\n",
        "        2: \"MultiplicativeNoise(multiplier=0.5, p=1)\",\n",
        "        3: \"RandomSizedBBoxSafeCrop(250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\",\n",
        "        4: \"Blur(blur_limit=(10, 10), p=0)\",\n",
        "        5: \"Transpose(1)\",\n",
        "        6: \"RandomRotate90(p=1)\",\n",
        "        7: \"ShiftScaleRotate(p=1)\",\n",
        "        8: \"VerticalFlip(p=1)\",\n",
        "        9: \"RandomBrightnessContrast(brightness_limit=0.2,p=1)\",\n",
        "    }\n",
        "\n",
        "    aug_channel_dict = {\n",
        "        -1: \"no augmentation\",\n",
        "        0: \"RandomBrightnessContrast(contrast_limit=0.2,p=1)\",\n",
        "        1: \"MultiplicativeNoise(multiplier=0.5, p=1)\",\n",
        "        2: \"Blur(blur_limit=(10, 10), p=0)\",\n",
        "        3: \"RandomBrightnessContrast(brightness_limit=0.2,p=1)\",\n",
        "        4: \"Superpixels (p_replace=0.1, n_segments=20, max_size=64, interpolation=1, p=1)\",\n",
        "        5: \"GaussNoise (var_limit=(10.0, 50.0), mean=0, p=1)\",\n",
        "    }\n",
        "\n",
        "    #######general functions###########\n",
        "    def __new__(cls, *args, **kwargs):\n",
        "        print(\"New instance of SciAugment.\")\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, aug_type: str = \"Default\", channel_aug: bool = False):\n",
        "        self.augmet_type = aug_type\n",
        "        print(\"Selected augmentation type: {}\".format(self.augmet_type))\n",
        "        if aug_type == \"Default\":\n",
        "            self.augment = [-1, 0, 3, 5, 6, 7, 8]\n",
        "            if channel_aug:\n",
        "                self.channel_augment = range(-1, 5, 1)\n",
        "\n",
        "        if aug_type == \"fluorescece_microscopy\":\n",
        "            self.augment = range(-1, 9, 1)\n",
        "            if channel_aug:\n",
        "                self.channel_augment = [-1, 1, 2, 3, 4, 5]\n",
        "\n",
        "        if aug_type == \"all\":\n",
        "            self.augment = range(-1, 9, 1)\n",
        "            if channel_aug:\n",
        "                self.channel_augment = range(-1, 5, 1)\n",
        "\n",
        "        if aug_type == \"no_augment\":\n",
        "            self.augment = [-1]\n",
        "            print(\n",
        "                \"No augment setting will only divide images and labels to train_data folder.\"\n",
        "            )\n",
        "            self.channel_augment = []\n",
        "\n",
        "        print(\"\\n\")\n",
        "        self.explain()\n",
        "\n",
        "    def explain(self):\n",
        "        print(\"Version: {}\".format(self.version))\n",
        "        print(\"\\n\")\n",
        "        print(\"Selected augmentation:\")\n",
        "        for aug in self.augment:\n",
        "            print(self.aug_dict[aug])\n",
        "\n",
        "        if self.channel_augment:\n",
        "            print(\"\\n\")\n",
        "            print(\"Selected channel wise augmentation:\")\n",
        "            for ch_aug in self.channel_augment:\n",
        "                print(self.aug_channel_dict[ch_aug])\n",
        "\n",
        "    def info(self):\n",
        "        print(\"Version: {}\".format(self.version))\n",
        "        print(\"\\n\")\n",
        "        print(\"Selected augmentation:\")\n",
        "        for aug in self.augment:\n",
        "            print(self.aug_dict[aug])\n",
        "\n",
        "        if self.channel_augment:\n",
        "            print(\"\\n\")\n",
        "            print(\"Selected channel wise augmentation:\")\n",
        "            for ch_aug in self.channel_augment:\n",
        "                print(self.aug_channel_dict[ch_aug])\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "        print(\"Source: {}\".format(self.source))\n",
        "        print(\"Author: {}\".format(self.author))\n",
        "\n",
        "    def read_image(self, images_path: str, filename: str):\n",
        "        \"\"\"\n",
        "        Uses OpenCV to read RGB images\n",
        "        :param images_path (str):\n",
        "        :param filename (str):\n",
        "        :return: RGB image\n",
        "        \"\"\"\n",
        "\n",
        "        # OpenCV uses BGR channels\n",
        "        img = cv2.imread(images_path + filename)\n",
        "        return img\n",
        "\n",
        "    def read_image_unchanged(self, images_path: str, filename: str):\n",
        "        \"\"\"\n",
        "        Uses OpenCV to read RGBA or 4 channel (maximum) images\n",
        "        :param images_path (str):\n",
        "        :param filename (str):\n",
        "        :return: RGB image\n",
        "        \"\"\"\n",
        "        # https://learnopencv.com/read-an-image-in-opencv-python-cpp/\n",
        "        # OpenCV uses BGR channels\n",
        "        img = cv2.imread(\n",
        "            images_path + filename, cv2.IMREAD_UNCHANGED | cv2.IMREAD_ANYDEPTH\n",
        "        )\n",
        "        return img\n",
        "\n",
        "    def read_yolo(self, filename: str) -> float:\n",
        "        \"\"\"\n",
        "        Reads YOLO type of object anotation for albumentation to read\n",
        "        :param filename (str):\n",
        "        :return yolo_coords:\n",
        "        \"\"\"\n",
        "        yolo_coords = []\n",
        "        with open(filename, \"r\") as fname:\n",
        "            for yolo in fname:\n",
        "                x = yolo.strip().split(\" \")\n",
        "                x.append(x[0])\n",
        "                x.pop(0)\n",
        "                x[0] = float(x[0])\n",
        "                x[1] = float(x[1])\n",
        "                x[2] = float(x[2])\n",
        "                x[3] = float(x[3])\n",
        "                # print(x)\n",
        "                yolo_coords.append(x)\n",
        "        return yolo_coords\n",
        "\n",
        "    def write_yolo(self, coords: float, name: str):\n",
        "        \"\"\"\n",
        "        Write YOLO type object coordinates to txt file\n",
        "        :param coords (float): list of coordinates\n",
        "        :param name (str): name of file to write to\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        with open(name + \".txt\", \"w\") as f:\n",
        "            for x in coords:\n",
        "                f.write(\"%s %s %s %s %s \\n\" % (x[-1], x[0], x[1], x[2], x[3]))\n",
        "        return 0\n",
        "\n",
        "    def create_train_data_folder(self):\n",
        "        try:\n",
        "            dir = \"train_data\"\n",
        "            if os.path.exists(dir):\n",
        "                print(\"Train_data folder already exists!\")  # , and will be removed.')\n",
        "                return 1\n",
        "                # shutil.rmtree(dir)\n",
        "            else:\n",
        "                os.mkdir(dir)\n",
        "\n",
        "            # info_path = dir + '/info.txt'\n",
        "            # with open(info_path, 'w') as f:\n",
        "            #   f.writelines(self.info())\n",
        "\n",
        "            dir_image_train = \"train_data/images/train\"\n",
        "            dir_image_val = \"train_data/images/val\"\n",
        "            dir_label_train = \"train_data/labels/train\"\n",
        "            dir_label_val = \"train_data/labels/val\"\n",
        "\n",
        "            os.mkdir(\"train_data/images\")\n",
        "            os.mkdir(\"train_data/labels\")\n",
        "            os.mkdir(dir_image_train)\n",
        "            os.mkdir(dir_image_val)\n",
        "            os.mkdir(dir_label_train)\n",
        "            os.mkdir(dir_label_val)\n",
        "\n",
        "            return 0\n",
        "        except:\n",
        "            print(\"Error while creating new train_data folder structure!\")\n",
        "            return 1\n",
        "\n",
        "    #########transform functions########\n",
        "    def get_transform(loop: int):\n",
        "        \"\"\"\n",
        "      !!!OLD FUNCTION, DO NOT USE!!!\n",
        "              Generating image an label augmentation for YOLO with name tag of augmentations.\n",
        "\n",
        "              :param loop (int): Number of augmentation from 0 to 8\n",
        "\n",
        "              :return:\n",
        "              A: transform function with BboxParams set for Yolo\n",
        "              name (string): Name where relevant to position is bit length 11 for:\n",
        "                1:Shift\n",
        "                2:Scale\n",
        "                3:Rotate\n",
        "                4:VerticalFlip\n",
        "                5:HorizontalFlip\n",
        "                6:RandomContrast\n",
        "                7:MultiplicativeNoise(multiplier=0.5, p=1)\n",
        "                8:RandomSizedBBoxSafeCrop (250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\n",
        "                9:Blur(blur_limit=(10, 10), p=0)\n",
        "                10:Transpose\n",
        "                11:RandomRotate90\n",
        "                12:RandomBrightness\n",
        "        \"\"\"\n",
        "        if loop == 0:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    A.HorizontalFlip(p=1),\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00001000000\"\n",
        "        elif loop == 1:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    A.RandomBrightnessContrast(p=1),\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000100000\"\n",
        "        elif loop == 2:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    A.HorizontalFlip(p=0),\n",
        "                    A.MultiplicativeNoise(multiplier=0.5, p=1),\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000010000\"\n",
        "        elif loop == 3:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    # A.CenterCrop(width=250, height=250, p=1)\n",
        "                    A.RandomSizedBBoxSafeCrop(\n",
        "                        250, 250, erosion_rate=0.0, interpolation=1, p=1.0\n",
        "                    )\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000001000\"\n",
        "        elif loop == 4:\n",
        "            transform = A.Compose(\n",
        "                [A.Blur(blur_limit=(10, 10), p=1)],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000000100\"\n",
        "        elif loop == 5:\n",
        "            transform = A.Compose(\n",
        "                [A.Transpose(p=11)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"00000000010\"\n",
        "        elif loop == 6:\n",
        "            transform = A.Compose(\n",
        "                [A.RandomRotate90(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"00000000001\"\n",
        "        elif loop == 7:\n",
        "            transform = A.Compose(\n",
        "                [A.ShiftScaleRotate(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"11100000000\"\n",
        "        elif loop == 8:\n",
        "            transform = A.Compose(\n",
        "                [A.VerticalFlip(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"00010000000\"\n",
        "        # elif loop == 7:\n",
        "        #     transform = A.Compose([\n",
        "        #         A.ImageCompression(quality_lower=0, quality_upper=1, p=0.2)\n",
        "        #     ], bbox_params=A.BboxParams(format='yolo'))\n",
        "        # elif loop == 8:\n",
        "        #     transform = A.Compose([\n",
        "        #         A.CoarseDropout(max_holes=50, max_height=40,\n",
        "        #                  max_width=40, fill_value=128, p=0)\n",
        "        #     ], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "        # transform = A.Compose([\n",
        "        #         A.HorizontalFlip(p=1),\n",
        "        #     ], bbox_params=A.BboxParams(format='yolo'))\n",
        "\n",
        "        return transform, name\n",
        "\n",
        "    def _h_flip():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.HorizontalFlip(p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000010000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_contrast():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.RandomBrightnessContrast(contrast_limit=0.2, p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000001000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _multi_noise():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.HorizontalFlip(p=0),\n",
        "                A.MultiplicativeNoise(multiplier=0.5, p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000000100000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_size_crop():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                # A.CenterCrop(width=250, height=250, p=1)\n",
        "                A.RandomSizedBBoxSafeCrop(\n",
        "                    250, 250, erosion_rate=0.0, interpolation=1, p=1.0\n",
        "                )\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000000010000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _im_blur():\n",
        "        transform = A.Compose(\n",
        "            [A.Blur(blur_limit=(10, 10), p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000001000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _im_transpose():\n",
        "        transform = A.Compose(\n",
        "            [A.Transpose(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000000100\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_rotate():\n",
        "        transform = A.Compose(\n",
        "            [A.RandomRotate90(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000000010\"\n",
        "        return transform, name\n",
        "\n",
        "    def _shift_scale_rotate():\n",
        "        transform = A.Compose(\n",
        "            [A.ShiftScaleRotate(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"111000000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _v_flip():\n",
        "        transform = A.Compose(\n",
        "            [A.VerticalFlip(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000100000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _no_augment():\n",
        "        transform = A.Compose(\n",
        "            [A.VerticalFlip(p=0)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_brightness():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000000000001\"\n",
        "        return transform, name\n",
        "\n",
        "    # for 16 bit A.ToFloat(max_value=65535.0),\n",
        "    #     \"\"\"\n",
        "    #       1:Shift\n",
        "    #       2:Scale\n",
        "    #       3:Rotate\n",
        "    #       4:VerticalFlip\n",
        "    #       5:HorizontalFlip\n",
        "    #       6:RandomBrightnessContrast\n",
        "    #       7:MultiplicativeNoise(multiplier=0.5, p=1)\n",
        "    #       8:RandomSizedBBoxSafeCrop (250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\n",
        "    #       9:Blur(blur_limit=(10, 10), p=0)\n",
        "    #       10:Transpose\n",
        "    #       11:RandomRotate90\n",
        "    #     \"\"\"\n",
        "\n",
        "    aug_functions = {\n",
        "        -1: _no_augment,\n",
        "        0: _h_flip,\n",
        "        1: _rand_contrast,\n",
        "        2: _multi_noise,\n",
        "        3: _rand_size_crop,\n",
        "        4: _im_blur,\n",
        "        5: _im_transpose,\n",
        "        6: _rand_rotate,\n",
        "        7: _shift_scale_rotate,\n",
        "        8: _v_flip,\n",
        "        9: _rand_brightness,\n",
        "    }\n",
        "\n",
        "    # add functions\n",
        "    def _no_augment_ch():\n",
        "        transform = A.Compose([A.VerticalFlip(p=0)])\n",
        "        name = \"-NA\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_contrast_ch():\n",
        "        transform = A.Compose([A.RandomBrightnessContrast(contrast_limit=0.2, p=1)])\n",
        "        name = \"-RC\"\n",
        "        return transform, name\n",
        "\n",
        "    def _multi_noise_ch():\n",
        "        transform = A.Compose([A.MultiplicativeNoise(multiplier=0.5, p=1)])\n",
        "        name = \"-MN\"\n",
        "        return transform, name\n",
        "\n",
        "    def _im_blur_ch():\n",
        "        transform = A.Compose([A.Blur(blur_limit=(10, 10), p=1)])\n",
        "        name = \"-B\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_brightness_ch():\n",
        "        transform = A.Compose([A.RandomBrightnessContrast(brightness_limit=0.2, p=1)])\n",
        "        name = \"-RB\"\n",
        "        return transform, name\n",
        "\n",
        "    def _superpixels_ch():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.Superpixels(\n",
        "                    p_replace=0.1, n_segments=20, max_size=64, interpolation=1, p=1\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        name = \"-SP\"\n",
        "        return transform, name\n",
        "\n",
        "    def _gauss_noise_ch():\n",
        "        transform = A.Compose([A.GaussNoise(var_limit=(10.0, 50.0), mean=0, p=1)])\n",
        "        name = \"-GN\"\n",
        "        return transform, name\n",
        "\n",
        "    channel_aug_functions = {\n",
        "        -1: _no_augment_ch,\n",
        "        0: _rand_contrast_ch,\n",
        "        1: _multi_noise_ch,\n",
        "        2: _im_blur_ch,\n",
        "        3: _rand_brightness_ch,\n",
        "        4: _superpixels_ch,\n",
        "        5: _gauss_noise_ch,\n",
        "    }\n",
        "\n",
        "    #####apply functions######\n",
        "    def augment_data(\n",
        "        self,\n",
        "        images_path: str,\n",
        "        train: float = 0.7,\n",
        "        image_format: str = \".png\",\n",
        "        output_image_format: str = \".jpg\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Augment input images and YOLO files as defined in get_transform() function and save then in train_dir prepared for training and test/val based on 70/30 rule.\n",
        "        :param images_path (str):\n",
        "        :param train (float): train/val parameter for generating training data set, default 70% train 30% val\n",
        "        :param image_format (str): image format name ('.png' default)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        # dir = 'train_data'\n",
        "\n",
        "        dir_image_train = \"train_data/images/train\"\n",
        "        dir_image_val = \"train_data/images/val\"\n",
        "        dir_label_train = \"train_data/labels/train\"\n",
        "        dir_label_val = \"train_data/labels/val\"\n",
        "\n",
        "        folder_err = self.create_train_data_folder()\n",
        "        if folder_err:\n",
        "            print(\"Please remove existing trin_data folder and try again.\")\n",
        "            return 1\n",
        "\n",
        "        # image_format = \".png\"\n",
        "        # train = 0.7\n",
        "        test = 1 - train\n",
        "        files_to_process = sorted(os.listdir(images_path))\n",
        "        print(\"Num of files: \" + str(len(files_to_process)))\n",
        "\n",
        "        #define empty title, ext, xmlTitle, txtExt\n",
        "        title = 'title'\n",
        "        ext = 'ext'\n",
        "        xmlTitle = 'xmlTitle'\n",
        "        txtExt = 'txtExt'\n",
        "\n",
        "        for filename in files_to_process:\n",
        "            print(\"Processing: \" + filename)\n",
        "\n",
        "            if filename.endswith(image_format.lower()) or filename.endswith(\n",
        "                image_format.upper()\n",
        "            ):\n",
        "                title, ext = os.path.splitext(os.path.basename(filename))\n",
        "                print(images_path)\n",
        "                print(filename)\n",
        "                image = self.read_image(images_path, filename)\n",
        "            if filename.endswith(\".txt\"):\n",
        "                xmlTitle, txtExt = os.path.splitext(os.path.basename(filename))\n",
        "                if xmlTitle == title:\n",
        "                    # bboxes = getCoordinates(filename)\n",
        "                    bboxes = self.read_yolo(images_path + xmlTitle + \".txt\")\n",
        "                    print(images_path + xmlTitle + \".txt\")\n",
        "                    for aug in self.augment:\n",
        "                        img = copy.deepcopy(image)\n",
        "                        transform, name_tag = self.aug_functions[aug]()\n",
        "                        dice = random.uniform(0, 1)\n",
        "                        # try:\n",
        "                        transformed = transform(image=img, bboxes=bboxes)\n",
        "                        transformed_image = transformed[\"image\"]\n",
        "                        transformed_bboxes = transformed[\"bboxes\"]\n",
        "                        name = (\n",
        "                            title\n",
        "                            + \"_\"\n",
        "                            + str(count)\n",
        "                            + \"_\"\n",
        "                            + name_tag\n",
        "                            + output_image_format\n",
        "                        )\n",
        "                        # print(name)\n",
        "                        if dice <= train:\n",
        "                            p_name = dir_image_train + \"/\" + name\n",
        "                        else:\n",
        "                            p_name = dir_image_val + \"/\" + name\n",
        "\n",
        "                        cv2.imwrite(p_name, transformed_image)\n",
        "                        print(\"Writing \" + name)\n",
        "                        # print(transformed_bboxes)\n",
        "                        # writeVoc(transformed_bboxes, count, transformed_image)\n",
        "                        # pTitle='/content/'+dir+'/'+title\n",
        "                        if dice <= train:\n",
        "                            p_title = (\n",
        "                                dir_label_train\n",
        "                                + \"/\"\n",
        "                                + title\n",
        "                                + \"_\"\n",
        "                                + str(count)\n",
        "                                + \"_\"\n",
        "                                + name_tag\n",
        "                            )\n",
        "                        else:\n",
        "                            p_title = (\n",
        "                                dir_label_val\n",
        "                                + \"/\"\n",
        "                                + title\n",
        "                                + \"_\"\n",
        "                                + str(count)\n",
        "                                + \"_\"\n",
        "                                + name_tag\n",
        "                            )\n",
        "\n",
        "                        self.write_yolo(transformed_bboxes, p_title)\n",
        "                        count = count + 1\n",
        "                        # except:\n",
        "                        # print(\"Bounding Box exception!!!\")\n",
        "                        # pass\n",
        "        print(\"Process created {} images\".format(count))\n",
        "\n",
        "    def augment_data_per_channel(\n",
        "        self,\n",
        "        images_path: str,\n",
        "        train: float = 0.7,\n",
        "        image_format: str = \".png\",\n",
        "        output_image_format: str = \".png\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Augment input images and YOLO files as defined in get_transform() function and save then in train_dir prepared for training and test/val based on 70/30 rule.\n",
        "        :param images_path (str):\n",
        "        :param train (float): train/val parameter for generating training data set, default 70% train 30% val\n",
        "        :param image_format (str): image format name ('.png' default)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        # dir = 'train_data'\n",
        "\n",
        "        dir_image_train = \"train_data/images/train\"\n",
        "        dir_image_val = \"train_data/images/val\"\n",
        "        dir_label_train = \"train_data/labels/train\"\n",
        "        dir_label_val = \"train_data/labels/val\"\n",
        "\n",
        "        folder_err = self.create_train_data_folder()\n",
        "        if folder_err:\n",
        "            print(\"Please remove existing trin_data folder and try again.\")\n",
        "            return 1\n",
        "\n",
        "        # image_format = \".png\"\n",
        "        # train = 0.7\n",
        "        test = 1 - train\n",
        "        files_to_process = sorted(os.listdir(images_path))\n",
        "        print(\"Num of files: \" + str(len(files_to_process)))\n",
        "\n",
        "        for filename in files_to_process:\n",
        "            print(\"Processing: \" + filename)\n",
        "\n",
        "            if filename.endswith(image_format.lower()) or filename.endswith(\n",
        "                image_format.upper()\n",
        "            ):\n",
        "                title, ext = os.path.splitext(os.path.basename(filename))\n",
        "                print(images_path)\n",
        "                print(filename)\n",
        "                image = self.read_image_unchanged(images_path, filename)\n",
        "            if filename.endswith(\".txt\"):\n",
        "                xmlTitle, txtExt = os.path.splitext(os.path.basename(filename))\n",
        "                if xmlTitle == title:\n",
        "                    # bboxes = getCoordinates(filename)\n",
        "                    bboxes = self.read_yolo(images_path + xmlTitle + \".txt\")\n",
        "                    print(images_path + xmlTitle + \".txt\")\n",
        "                    for aug in self.augment:\n",
        "                        img = copy.deepcopy(image)\n",
        "                        transform, name_tag = self.aug_functions[aug]()\n",
        "                        dice = random.uniform(0, 1)\n",
        "                        #####apply also channel augmentation#####\n",
        "                        # try:\n",
        "                        transformed = transform(image=img, bboxes=bboxes)\n",
        "                        transformed_image = transformed[\"image\"]\n",
        "                        transformed_bboxes = transformed[\"bboxes\"]\n",
        "\n",
        "                        # go through channel transports\n",
        "                        for ch_aug in self.channel_augment:\n",
        "\n",
        "                            transform_ch, ch_name_tag = self.channel_aug_functions[\n",
        "                                ch_aug\n",
        "                            ]()\n",
        "\n",
        "                            # split channels\n",
        "                            im_split = cv2.split(transformed_image)\n",
        "\n",
        "                            for ch in range(0, len(im_split), 1):\n",
        "                                channel = im_split[ch]\n",
        "\n",
        "                                transformed = transform_ch(image=channel)\n",
        "                                transformed_channel = transformed[\"image\"]\n",
        "\n",
        "                                im_merge = copy.deepcopy(im_split)\n",
        "                                im_merge[ch] = transformed_channel\n",
        "                                merged_transformed = cv2.merge(im_merge)\n",
        "                                name_tag_ch = \"_ch-\" + str(ch + 1) + ch_name_tag\n",
        "                                # print(name_ch)\n",
        "                                # cv2_imshow(merged)\n",
        "                                # save\n",
        "                                name = (\n",
        "                                    title\n",
        "                                    + \"_\"\n",
        "                                    + str(count)\n",
        "                                    + \"_\"\n",
        "                                    + name_tag\n",
        "                                    + name_tag_ch\n",
        "                                )\n",
        "                                # print(name)\n",
        "                                if dice <= train:\n",
        "                                    p_name = (\n",
        "                                        dir_image_train\n",
        "                                        + \"/\"\n",
        "                                        + name\n",
        "                                        + output_image_format\n",
        "                                    )\n",
        "                                else:\n",
        "                                    p_name = (\n",
        "                                        dir_image_val + \"/\" + name + output_image_format\n",
        "                                    )\n",
        "\n",
        "                                cv2.imwrite(p_name, merged_transformed)\n",
        "                                print(\"Writing \" + name)\n",
        "                                # print(transformed_bboxes)\n",
        "                                # writeVoc(transformed_bboxes, count, transformed_image)\n",
        "                                # pTitle='/content/'+dir+'/'+title\n",
        "                                if dice <= train:\n",
        "                                    p_title = dir_label_train + \"/\" + name\n",
        "                                else:\n",
        "                                    p_title = dir_label_val + \"/\" + name\n",
        "\n",
        "                                self.write_yolo(transformed_bboxes, p_title)\n",
        "                                count = count + 1\n",
        "                        # except:\n",
        "                        # print(\"Augmentation exception!!!\")\n",
        "                        # pass\n",
        "        print(\"Process created {} images\".format(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcqbG04kand"
      },
      "outputs": [],
      "source": [
        "from SciAugment.utilities.SciAug_tools import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W482j5sQkdUW"
      },
      "outputs": [],
      "source": [
        "#@markdown Specifie a path to folder with images and YOLO annotations\n",
        "input_images_folder = '/content/YOLOBee/Yolov5/frames_04+frames_2/'  # @param{type: 'string'}\n",
        "input_image_format = '.jpg'  # @param{type: 'string'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM88DVS_kgU2",
        "outputId": "6a087cf8-59a8-4be6-d33c-811fa3c7303c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New instance of SciAugment.\n",
            "Selected augmentation type: Default\n",
            "\n",
            "\n",
            "Version: 0.1.0\n",
            "\n",
            "\n",
            "Selected augmentation:\n",
            "HorizontalFlip(p=1)\n",
            "RandomSizedBBoxSafeCrop(250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\n",
            "Transpose(1)\n",
            "RandomRotate90(p=1)\n",
            "ShiftScaleRotate(p=1)\n",
            "VerticalFlip(p=1)\n"
          ]
        }
      ],
      "source": [
        "aug = SciAugment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkj65OgqOIaJ",
        "outputId": "f9f8e971-0bc3-47d0-a58f-243a562e9587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FX4HqISWkjKu",
        "outputId": "7ecdd5e4-0ec5-4dee-e809-f618aa306112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of files: 54\n",
            "Processing: Copie de frame_0002.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0002.jpg\n",
            "Processing: Copie de frame_0002.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0002.txt\n",
            "Writing Copie de frame_0002_0_00001000000.jpg\n",
            "Writing Copie de frame_0002_1_00000001000.jpg\n",
            "Writing Copie de frame_0002_2_00000000010.jpg\n",
            "Writing Copie de frame_0002_3_00000000001.jpg\n",
            "Writing Copie de frame_0002_4_11100000000.jpg\n",
            "Writing Copie de frame_0002_5_00010000000.jpg\n",
            "Processing: Copie de frame_0003.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0003.jpg\n",
            "Processing: Copie de frame_0003.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0003.txt\n",
            "Writing Copie de frame_0003_6_00001000000.jpg\n",
            "Writing Copie de frame_0003_7_00000001000.jpg\n",
            "Writing Copie de frame_0003_8_00000000010.jpg\n",
            "Writing Copie de frame_0003_9_00000000001.jpg\n",
            "Writing Copie de frame_0003_10_11100000000.jpg\n",
            "Writing Copie de frame_0003_11_00010000000.jpg\n",
            "Processing: Copie de frame_0004.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0004.jpg\n",
            "Processing: Copie de frame_0004.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0004.txt\n",
            "Writing Copie de frame_0004_12_00001000000.jpg\n",
            "Writing Copie de frame_0004_13_00000001000.jpg\n",
            "Writing Copie de frame_0004_14_00000000010.jpg\n",
            "Writing Copie de frame_0004_15_00000000001.jpg\n",
            "Writing Copie de frame_0004_16_11100000000.jpg\n",
            "Writing Copie de frame_0004_17_00010000000.jpg\n",
            "Processing: Copie de frame_0005.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0005.jpg\n",
            "Processing: Copie de frame_0005.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0005.txt\n",
            "Writing Copie de frame_0005_18_00001000000.jpg\n",
            "Writing Copie de frame_0005_19_00000001000.jpg\n",
            "Writing Copie de frame_0005_20_00000000010.jpg\n",
            "Writing Copie de frame_0005_21_00000000001.jpg\n",
            "Writing Copie de frame_0005_22_11100000000.jpg\n",
            "Writing Copie de frame_0005_23_00010000000.jpg\n",
            "Processing: Copie de frame_0006.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0006.jpg\n",
            "Processing: Copie de frame_0006.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0006.txt\n",
            "Writing Copie de frame_0006_24_00001000000.jpg\n",
            "Writing Copie de frame_0006_25_00000001000.jpg\n",
            "Writing Copie de frame_0006_26_00000000010.jpg\n",
            "Writing Copie de frame_0006_27_00000000001.jpg\n",
            "Writing Copie de frame_0006_28_11100000000.jpg\n",
            "Writing Copie de frame_0006_29_00010000000.jpg\n",
            "Processing: Copie de frame_0007.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0007.jpg\n",
            "Processing: Copie de frame_0007.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0007.txt\n",
            "Writing Copie de frame_0007_30_00001000000.jpg\n",
            "Writing Copie de frame_0007_31_00000001000.jpg\n",
            "Writing Copie de frame_0007_32_00000000010.jpg\n",
            "Writing Copie de frame_0007_33_00000000001.jpg\n",
            "Writing Copie de frame_0007_34_11100000000.jpg\n",
            "Writing Copie de frame_0007_35_00010000000.jpg\n",
            "Processing: Copie de frame_0008.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0008.jpg\n",
            "Processing: Copie de frame_0008.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0008.txt\n",
            "Writing Copie de frame_0008_36_00001000000.jpg\n",
            "Writing Copie de frame_0008_37_00000001000.jpg\n",
            "Writing Copie de frame_0008_38_00000000010.jpg\n",
            "Writing Copie de frame_0008_39_00000000001.jpg\n",
            "Writing Copie de frame_0008_40_11100000000.jpg\n",
            "Writing Copie de frame_0008_41_00010000000.jpg\n",
            "Processing: Copie de frame_0009.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0009.jpg\n",
            "Processing: Copie de frame_0009.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0009.txt\n",
            "Writing Copie de frame_0009_42_00001000000.jpg\n",
            "Writing Copie de frame_0009_43_00000001000.jpg\n",
            "Writing Copie de frame_0009_44_00000000010.jpg\n",
            "Writing Copie de frame_0009_45_00000000001.jpg\n",
            "Writing Copie de frame_0009_46_11100000000.jpg\n",
            "Writing Copie de frame_0009_47_00010000000.jpg\n",
            "Processing: Copie de frame_0010.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0010.jpg\n",
            "Processing: Copie de frame_0010.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0010.txt\n",
            "Writing Copie de frame_0010_48_00001000000.jpg\n",
            "Writing Copie de frame_0010_49_00000001000.jpg\n",
            "Writing Copie de frame_0010_50_00000000010.jpg\n",
            "Writing Copie de frame_0010_51_00000000001.jpg\n",
            "Writing Copie de frame_0010_52_11100000000.jpg\n",
            "Writing Copie de frame_0010_53_00010000000.jpg\n",
            "Processing: Copie de frame_0011.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0011.jpg\n",
            "Processing: Copie de frame_0011.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0011.txt\n",
            "Writing Copie de frame_0011_54_00001000000.jpg\n",
            "Writing Copie de frame_0011_55_00000001000.jpg\n",
            "Writing Copie de frame_0011_56_00000000010.jpg\n",
            "Writing Copie de frame_0011_57_00000000001.jpg\n",
            "Writing Copie de frame_0011_58_11100000000.jpg\n",
            "Writing Copie de frame_0011_59_00010000000.jpg\n",
            "Processing: Copie de frame_0012.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0012.jpg\n",
            "Processing: Copie de frame_0012.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0012.txt\n",
            "Writing Copie de frame_0012_60_00001000000.jpg\n",
            "Writing Copie de frame_0012_61_00000001000.jpg\n",
            "Writing Copie de frame_0012_62_00000000010.jpg\n",
            "Writing Copie de frame_0012_63_00000000001.jpg\n",
            "Writing Copie de frame_0012_64_11100000000.jpg\n",
            "Writing Copie de frame_0012_65_00010000000.jpg\n",
            "Processing: Copie de frame_0013.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0013.jpg\n",
            "Processing: Copie de frame_0013.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0013.txt\n",
            "Writing Copie de frame_0013_66_00001000000.jpg\n",
            "Writing Copie de frame_0013_67_00000001000.jpg\n",
            "Writing Copie de frame_0013_68_00000000010.jpg\n",
            "Writing Copie de frame_0013_69_00000000001.jpg\n",
            "Writing Copie de frame_0013_70_11100000000.jpg\n",
            "Writing Copie de frame_0013_71_00010000000.jpg\n",
            "Processing: Copie de frame_0014.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0014.jpg\n",
            "Processing: Copie de frame_0014.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0014.txt\n",
            "Writing Copie de frame_0014_72_00001000000.jpg\n",
            "Writing Copie de frame_0014_73_00000001000.jpg\n",
            "Writing Copie de frame_0014_74_00000000010.jpg\n",
            "Writing Copie de frame_0014_75_00000000001.jpg\n",
            "Writing Copie de frame_0014_76_11100000000.jpg\n",
            "Writing Copie de frame_0014_77_00010000000.jpg\n",
            "Processing: Copie de frame_0015.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0015.jpg\n",
            "Processing: Copie de frame_0015.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0015.txt\n",
            "Writing Copie de frame_0015_78_00001000000.jpg\n",
            "Writing Copie de frame_0015_79_00000001000.jpg\n",
            "Writing Copie de frame_0015_80_00000000010.jpg\n",
            "Writing Copie de frame_0015_81_00000000001.jpg\n",
            "Writing Copie de frame_0015_82_11100000000.jpg\n",
            "Writing Copie de frame_0015_83_00010000000.jpg\n",
            "Processing: Copie de frame_0015_1.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0015_1.jpg\n",
            "Processing: Copie de frame_0015_1.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0015_1.txt\n",
            "Writing Copie de frame_0015_1_84_00001000000.jpg\n",
            "Writing Copie de frame_0015_1_85_00000001000.jpg\n",
            "Writing Copie de frame_0015_1_86_00000000010.jpg\n",
            "Writing Copie de frame_0015_1_87_00000000001.jpg\n",
            "Writing Copie de frame_0015_1_88_11100000000.jpg\n",
            "Writing Copie de frame_0015_1_89_00010000000.jpg\n",
            "Processing: Copie de frame_0030_1 (1).jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0030_1 (1).jpg\n",
            "Processing: Copie de frame_0030_1 (1).txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0030_1 (1).txt\n",
            "Writing Copie de frame_0030_1 (1)_90_00001000000.jpg\n",
            "Writing Copie de frame_0030_1 (1)_91_00000001000.jpg\n",
            "Writing Copie de frame_0030_1 (1)_92_00000000010.jpg\n",
            "Writing Copie de frame_0030_1 (1)_93_00000000001.jpg\n",
            "Writing Copie de frame_0030_1 (1)_94_11100000000.jpg\n",
            "Writing Copie de frame_0030_1 (1)_95_00010000000.jpg\n",
            "Processing: Copie de frame_2_0000.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0000.jpg\n",
            "Processing: Copie de frame_2_0000.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0000.txt\n",
            "Writing Copie de frame_2_0000_96_00001000000.jpg\n",
            "Writing Copie de frame_2_0000_97_00000001000.jpg\n",
            "Writing Copie de frame_2_0000_98_00000000010.jpg\n",
            "Writing Copie de frame_2_0000_99_00000000001.jpg\n",
            "Writing Copie de frame_2_0000_100_11100000000.jpg\n",
            "Writing Copie de frame_2_0000_101_00010000000.jpg\n",
            "Processing: Copie de frame_2_0001.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0001.jpg\n",
            "Processing: Copie de frame_2_0001.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0001.txt\n",
            "Writing Copie de frame_2_0001_102_00001000000.jpg\n",
            "Writing Copie de frame_2_0001_103_00000001000.jpg\n",
            "Writing Copie de frame_2_0001_104_00000000010.jpg\n",
            "Writing Copie de frame_2_0001_105_00000000001.jpg\n",
            "Writing Copie de frame_2_0001_106_11100000000.jpg\n",
            "Writing Copie de frame_2_0001_107_00010000000.jpg\n",
            "Processing: Copie de frame_2_0021.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0021.jpg\n",
            "Processing: Copie de frame_2_0021.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0021.txt\n",
            "Writing Copie de frame_2_0021_108_00001000000.jpg\n",
            "Writing Copie de frame_2_0021_109_00000001000.jpg\n",
            "Writing Copie de frame_2_0021_110_00000000010.jpg\n",
            "Writing Copie de frame_2_0021_111_00000000001.jpg\n",
            "Writing Copie de frame_2_0021_112_11100000000.jpg\n",
            "Writing Copie de frame_2_0021_113_00010000000.jpg\n",
            "Processing: Copie de frame_2_0022.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0022.jpg\n",
            "Processing: Copie de frame_2_0022.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0022.txt\n",
            "Writing Copie de frame_2_0022_114_00001000000.jpg\n",
            "Writing Copie de frame_2_0022_115_00000001000.jpg\n",
            "Writing Copie de frame_2_0022_116_00000000010.jpg\n",
            "Writing Copie de frame_2_0022_117_00000000001.jpg\n",
            "Writing Copie de frame_2_0022_118_11100000000.jpg\n",
            "Writing Copie de frame_2_0022_119_00010000000.jpg\n",
            "Processing: Copie de frame_2_0023.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0023.jpg\n",
            "Processing: Copie de frame_2_0023.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0023.txt\n",
            "Writing Copie de frame_2_0023_120_00001000000.jpg\n",
            "Writing Copie de frame_2_0023_121_00000001000.jpg\n",
            "Writing Copie de frame_2_0023_122_00000000010.jpg\n",
            "Writing Copie de frame_2_0023_123_00000000001.jpg\n",
            "Writing Copie de frame_2_0023_124_11100000000.jpg\n",
            "Writing Copie de frame_2_0023_125_00010000000.jpg\n",
            "Processing: Copie de frame_2_0024.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0024.jpg\n",
            "Processing: Copie de frame_2_0024.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0024.txt\n",
            "Writing Copie de frame_2_0024_126_00001000000.jpg\n",
            "Writing Copie de frame_2_0024_127_00000001000.jpg\n",
            "Writing Copie de frame_2_0024_128_00000000010.jpg\n",
            "Writing Copie de frame_2_0024_129_00000000001.jpg\n",
            "Writing Copie de frame_2_0024_130_11100000000.jpg\n",
            "Writing Copie de frame_2_0024_131_00010000000.jpg\n",
            "Processing: Copie de frame_2_0025.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0025.jpg\n",
            "Processing: Copie de frame_2_0025.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0025.txt\n",
            "Writing Copie de frame_2_0025_132_00001000000.jpg\n",
            "Writing Copie de frame_2_0025_133_00000001000.jpg\n",
            "Writing Copie de frame_2_0025_134_00000000010.jpg\n",
            "Writing Copie de frame_2_0025_135_00000000001.jpg\n",
            "Writing Copie de frame_2_0025_136_11100000000.jpg\n",
            "Writing Copie de frame_2_0025_137_00010000000.jpg\n",
            "Processing: Copie de frame_2_0026.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0026.jpg\n",
            "Processing: Copie de frame_2_0026.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0026.txt\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Processing: Copie de frame_2_0027.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0027.jpg\n",
            "Processing: Copie de frame_2_0027.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0027.txt\n",
            "Writing Copie de frame_2_0027_138_00001000000.jpg\n",
            "Writing Copie de frame_2_0027_139_00000001000.jpg\n",
            "Writing Copie de frame_2_0027_140_00000000010.jpg\n",
            "Writing Copie de frame_2_0027_141_00000000001.jpg\n",
            "Writing Copie de frame_2_0027_142_11100000000.jpg\n",
            "Writing Copie de frame_2_0027_143_00010000000.jpg\n",
            "Processing: Copie de frame_2_0028.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0028.jpg\n",
            "Processing: Copie de frame_2_0028.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0028.txt\n",
            "Writing Copie de frame_2_0028_144_00001000000.jpg\n",
            "Writing Copie de frame_2_0028_145_00000001000.jpg\n",
            "Writing Copie de frame_2_0028_146_00000000010.jpg\n",
            "Writing Copie de frame_2_0028_147_00000000001.jpg\n",
            "Writing Copie de frame_2_0028_148_11100000000.jpg\n",
            "Writing Copie de frame_2_0028_149_00010000000.jpg\n",
            "Processing: Copie de frame_2_0029.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0029.jpg\n",
            "Processing: Copie de frame_2_0029.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0029.txt\n",
            "Writing Copie de frame_2_0029_150_00001000000.jpg\n",
            "Writing Copie de frame_2_0029_151_00000001000.jpg\n",
            "Writing Copie de frame_2_0029_152_00000000010.jpg\n",
            "Writing Copie de frame_2_0029_153_00000000001.jpg\n",
            "Writing Copie de frame_2_0029_154_11100000000.jpg\n",
            "Writing Copie de frame_2_0029_155_00010000000.jpg\n"
          ]
        }
      ],
      "source": [
        "aug.augment_data(images_path=input_images_folder, image_format=input_image_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "IBptatA9gLBl",
        "outputId": "5667a03a-f818-4eea-b702-205ce75c4f42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YOLOBee/Yolov5/train_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.copytree('/content/train_data','YOLOBee/Yolov5/train_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmrIkUjZ-v1z"
      },
      "source": [
        "Training\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To launch the training of the neural network, you need to download the repository yolov5 from ultralytics."
      ],
      "metadata": {
        "id": "jbjP882PRi-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKLa7ME8QiXX",
        "outputId": "6a40102e-e7ff-4424-c272-93311c8041e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtrain_data\u001b[0m/  \u001b[01;34mYOLOBee\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VucocSGBjw-U",
        "outputId": "864867ec-6524-45d8-97db-e72274834c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOBee/Yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd /content/YOLOBee/Yolov5/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJ53NTz-yXc",
        "outputId": "d7ce9f8c-d0a7-4bb9-c34d-e3bd18715aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-338-gff063284 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.8/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "\n",
        "%pip install -qr /content/YOLOBee/Yolov5/yolov5/requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "\n",
        "from yolov5 import utils\n",
        "\n",
        "%cd yolov5\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything is installed, now the training can began. This is the command line to train the neural network. It uses the pretrained weights of yolov5s and it only training for 100 epochs. If you want the model to be really efficiant you can change the parameters."
      ],
      "metadata": {
        "id": "SiBjTlL7Vda9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgyT4zP3J43Q",
        "outputId": "32b90113-36ac-4f74-9793-5c5100e7c723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-10 11:06:12.091914: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-10 11:06:12.091987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-10 11:06:12.216326: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../class1.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-338-gff063284 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 236MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.75G total, 0.22G reserved, 0.05G allocated, 14.47G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     7022326       15.95         0.306         30.96         142.7        (1, 3, 640, 640)                    list\n",
            "     7022326       31.89         0.430         42.74          58.5        (2, 3, 640, 640)                    list\n",
            "     7022326       63.78         0.826         39.77         61.92        (4, 3, 640, 640)                    list\n",
            "     7022326       127.6         1.592         44.83         68.49        (8, 3, 640, 640)                    list\n",
            "     7022326       255.1         3.131         74.31         91.13       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 60 for CUDA:0 11.77G/14.75G (80%) ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
            "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.11 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/YOLOBee/Yolov5/train_data/labels/train... 103 images, 0 backgrounds, 0 corrupt: 100% 103/103 [00:00<00:00, 322.00it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/YOLOBee/Yolov5/train_data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 103/103 [00:03<00:00, 32.33it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLOBee/Yolov5/train_data/labels/val... 53 images, 0 backgrounds, 0 corrupt: 100% 53/53 [00:00<00:00, 301.60it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/YOLOBee/Yolov5/train_data/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 53/53 [00:02<00:00, 19.01it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.63 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      12.6G     0.1398    0.03255          0        308        640: 100% 2/2 [00:04<00:00,  2.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.55s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      12.6G     0.1363    0.03349          0        320        640: 100% 2/2 [00:01<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 3.150s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.89s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      12.6G      0.138    0.03173          0        286        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.37s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      12.6G     0.1333    0.03163          0        337        640: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.13s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      12.6G     0.1321    0.02984          0        300        640: 100% 2/2 [00:01<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 3.150s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.57s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      12.6G     0.1295    0.03032          0        394        640: 100% 2/2 [00:01<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.88s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      12.6G     0.1297     0.0294          0        348        640: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.47s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      12.6G     0.1265    0.02727          0        307        640: 100% 2/2 [00:01<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.11s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      12.6G      0.127     0.0259          0        357        640: 100% 2/2 [00:01<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.72s/it]\n",
            "                   all         53        205   0.000126    0.00976   6.92e-05   2.58e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      12.6G     0.1267    0.02551          0        315        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.38s/it]\n",
            "                   all         53        205   0.000126    0.00976   6.54e-05   9.75e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      12.6G     0.1253     0.0253          0        318        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.22s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      12.6G     0.1211    0.02477          0        329        640: 100% 2/2 [00:01<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.09s/it]\n",
            "                   all         53        205          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      12.6G     0.1239      0.023          0        362        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.90s/it]\n",
            "                   all         53        205   6.29e-05    0.00488   3.99e-05   3.99e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      12.6G     0.1226    0.02629          0        305        640: 100% 2/2 [00:01<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.43s/it]\n",
            "                   all         53        205   0.000126    0.00976   7.18e-05   1.52e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      12.6G     0.1238    0.02466          0        320        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.17s/it]\n",
            "                   all         53        205   6.29e-05    0.00488   3.53e-05   1.41e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      12.6G     0.1236     0.0274          0        343        640: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "                   all         53        205   0.000126    0.00976   6.39e-05   1.59e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      12.6G     0.1219    0.02474          0        349        640: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         53        205   6.29e-05    0.00488   3.17e-05   3.17e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      12.6G     0.1192    0.02515          0        336        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.14it/s]\n",
            "                   all         53        205   0.000314     0.0244   0.000171   3.01e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      12.6G     0.1134    0.02908          0        295        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.08s/it]\n",
            "                   all         53        205   0.000692     0.0537   0.000391   7.81e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      12.6G     0.1164    0.02687          0        349        640: 100% 2/2 [00:01<00:00,  1.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.28s/it]\n",
            "                   all         53        205    0.00151      0.117   0.000926    0.00018\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      12.6G     0.1073    0.02633          0        307        640: 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "                   all         53        205    0.00157      0.122    0.00102   0.000209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      12.6G     0.1111    0.02635          0        312        640: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "                   all         53        205    0.00277      0.215    0.00315    0.00057\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      12.6G     0.1062    0.02772          0        330        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         53        205    0.00321      0.249    0.00298   0.000627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      12.6G      0.107    0.02613          0        343        640: 100% 2/2 [00:01<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.68s/it]\n",
            "                   all         53        205    0.00491       0.38    0.00683    0.00143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      12.6G     0.1041    0.02928          0        329        640: 100% 2/2 [00:01<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.16s/it]\n",
            "                   all         53        205     0.0061      0.473     0.0104    0.00218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      12.6G     0.1008     0.0304          0        341        640: 100% 2/2 [00:01<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         53        205    0.00635      0.493     0.0202    0.00427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      12.6G    0.09763     0.0278          0        344        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.15it/s]\n",
            "                   all         53        205     0.0297      0.346     0.0225    0.00482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      12.6G    0.07088     0.0267          0        356        640: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.13it/s]\n",
            "                   all         53        205     0.0729      0.171     0.0283    0.00555\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      12.6G     0.1083    0.02557          0        272        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.45s/it]\n",
            "                   all         53        205      0.112      0.151     0.0473    0.00987\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      12.6G     0.1015    0.02511          0        284        640: 100% 2/2 [00:01<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.15s/it]\n",
            "                   all         53        205      0.195      0.171     0.0797     0.0167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      12.6G    0.09746    0.02811          0        336        640: 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.17it/s]\n",
            "                   all         53        205      0.276      0.203      0.105     0.0241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      12.6G    0.09397    0.02832          0        326        640: 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.14it/s]\n",
            "                   all         53        205      0.327      0.244      0.142     0.0301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      12.6G    0.08954     0.0279          0        323        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.25it/s]\n",
            "                   all         53        205       0.27      0.239      0.133     0.0283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      12.6G    0.08904    0.02756          0        287        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "                   all         53        205      0.259      0.263      0.171     0.0396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      12.6G    0.08853    0.02622          0        314        640: 100% 2/2 [00:01<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.95s/it]\n",
            "                   all         53        205      0.242      0.273      0.152     0.0362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      12.6G    0.08732     0.0256          0        342        640: 100% 2/2 [00:01<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "                   all         53        205      0.301      0.313      0.227     0.0502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      12.6G       0.09    0.02851          0        327        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                   all         53        205      0.254      0.312      0.186      0.047\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      12.6G    0.08769    0.02814          0        338        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         53        205       0.18      0.234      0.121     0.0287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      12.6G    0.08264     0.0249          0        323        640: 100% 2/2 [00:01<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all         53        205      0.342      0.444      0.254     0.0626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      12.6G    0.08989    0.02475          0        297        640: 100% 2/2 [00:01<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.26s/it]\n",
            "                   all         53        205      0.315      0.415      0.281     0.0761\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      12.6G    0.08352    0.02523          0        343        640: 100% 2/2 [00:01<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.77s/it]\n",
            "                   all         53        205      0.346      0.493        0.3     0.0758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      12.6G    0.08438    0.02497          0        331        640: 100% 2/2 [00:01<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.30it/s]\n",
            "                   all         53        205      0.133      0.302     0.0927     0.0217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      12.6G    0.08025    0.02504          0        331        640: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.28it/s]\n",
            "                   all         53        205      0.234      0.522      0.238      0.063\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      12.6G     0.0779     0.0242          0        324        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         53        205      0.339      0.332      0.279     0.0661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      12.6G    0.08055    0.02391          0        330        640: 100% 2/2 [00:01<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.33it/s]\n",
            "                   all         53        205      0.343      0.551      0.379      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      12.6G    0.07653    0.02354          0        282        640: 100% 2/2 [00:01<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.68s/it]\n",
            "                   all         53        205      0.265      0.566      0.299     0.0787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      12.6G    0.07119    0.02329          0        307        640: 100% 2/2 [00:01<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.79s/it]\n",
            "                   all         53        205      0.258       0.59      0.288     0.0631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      12.6G     0.0746    0.02463          0        325        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         53        205       0.38      0.635      0.377      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      12.6G    0.07634      0.021          0        262        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.28it/s]\n",
            "                   all         53        205      0.324      0.678      0.359      0.109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      12.6G    0.06857    0.02498          0        303        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         53        205      0.333       0.62      0.332     0.0985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      12.6G    0.05995    0.02274          0        315        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.28it/s]\n",
            "                   all         53        205      0.216      0.522       0.19     0.0449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      12.6G    0.06666    0.02157          0        263        640: 100% 2/2 [00:01<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.45s/it]\n",
            "                   all         53        205      0.381      0.459      0.295     0.0739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      12.6G    0.06457    0.02221          0        355        640: 100% 2/2 [00:01<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.83s/it]\n",
            "                   all         53        205      0.573      0.717      0.604      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      12.6G    0.06541    0.02399          0        400        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         53        205      0.512      0.685       0.52      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      12.6G    0.07486    0.02318          0        296        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                   all         53        205      0.516      0.746      0.554      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      12.6G    0.06391    0.02351          0        277        640: 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all         53        205      0.454      0.617       0.44      0.122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      12.6G    0.06701     0.0239          0        356        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.28it/s]\n",
            "                   all         53        205       0.49       0.62      0.447      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      12.6G    0.06529    0.02201          0        288        640: 100% 2/2 [00:01<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "                   all         53        205      0.444      0.639      0.441      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      12.6G    0.06748    0.02276          0        313        640: 100% 2/2 [00:01<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.30s/it]\n",
            "                   all         53        205      0.534      0.663      0.485       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      12.6G    0.06356    0.02179          0        362        640: 100% 2/2 [00:01<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.27it/s]\n",
            "                   all         53        205      0.548      0.776      0.576      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      12.6G    0.06359    0.02072          0        297        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.36it/s]\n",
            "                   all         53        205      0.562      0.776      0.605      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      12.6G    0.06135    0.02318          0        340        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.35it/s]\n",
            "                   all         53        205      0.526        0.8      0.563        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      12.6G    0.06114    0.02117          0        309        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "                   all         53        205      0.664      0.741      0.661      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      12.6G    0.05984    0.02139          0        320        640: 100% 2/2 [00:01<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.81s/it]\n",
            "                   all         53        205      0.635      0.782      0.665      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      12.6G     0.0588    0.02229          0        381        640: 100% 2/2 [00:01<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.17s/it]\n",
            "                   all         53        205      0.648      0.781      0.662      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      12.6G     0.0573    0.02171          0        360        640: 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         53        205      0.678       0.78      0.715      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      12.6G    0.05409    0.02109          0        334        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "                   all         53        205       0.51      0.834      0.592      0.228\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      12.6G    0.05432    0.02058          0        310        640: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                   all         53        205      0.682      0.815       0.75      0.273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      12.6G    0.04935     0.0214          0        327        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all         53        205      0.586      0.816      0.665      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      12.6G    0.05976    0.02087          0        281        640: 100% 2/2 [00:01<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.78s/it]\n",
            "                   all         53        205      0.825       0.82      0.821      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      12.6G    0.05617    0.02193          0        346        640: 100% 2/2 [00:01<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.11s/it]\n",
            "                   all         53        205      0.752       0.83      0.768      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      12.6G    0.05543    0.02213          0        352        640: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
            "                   all         53        205       0.82      0.829      0.841      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      12.6G    0.05417    0.02124          0        349        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.33it/s]\n",
            "                   all         53        205      0.798       0.81      0.817      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      12.6G    0.05048    0.02182          0        404        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.40it/s]\n",
            "                   all         53        205      0.758      0.824      0.775      0.266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      12.6G    0.05398    0.01915          0        262        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.24s/it]\n",
            "                   all         53        205       0.86      0.839      0.838      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      12.6G    0.05187    0.02058          0        335        640: 100% 2/2 [00:01<00:00,  1.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.80s/it]\n",
            "                   all         53        205      0.687      0.751      0.686      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      12.6G    0.05312     0.0211          0        302        640: 100% 2/2 [00:01<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.22s/it]\n",
            "                   all         53        205      0.869      0.841      0.878      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      12.6G    0.04885    0.02023          0        320        640: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.40it/s]\n",
            "                   all         53        205      0.901      0.849      0.891      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      12.6G    0.05611    0.02064          0        366        640: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         53        205      0.881      0.839      0.878      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      12.6G    0.05102     0.0207          0        316        640: 100% 2/2 [00:01<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n",
            "                   all         53        205      0.822      0.811      0.824      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      12.6G    0.05139    0.01972          0        316        640: 100% 2/2 [00:01<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.51s/it]\n",
            "                   all         53        205      0.904      0.871      0.919      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      12.6G    0.04846    0.02102          0        373        640: 100% 2/2 [00:01<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.68s/it]\n",
            "                   all         53        205      0.883      0.844      0.874      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      12.6G     0.0488    0.01746          0        268        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.30it/s]\n",
            "                   all         53        205      0.906      0.844      0.892       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      12.6G    0.04991    0.01973          0        329        640: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         53        205      0.884      0.839      0.876      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      12.6G    0.04869     0.0179          0        338        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.34it/s]\n",
            "                   all         53        205      0.885      0.849       0.88      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      12.6G    0.04928    0.01967          0        295        640: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.33it/s]\n",
            "                   all         53        205      0.877      0.878      0.884      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      12.6G    0.04679    0.01861          0        317        640: 100% 2/2 [00:01<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.38s/it]\n",
            "                   all         53        205      0.875      0.888      0.906      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      12.6G    0.04486    0.01883          0        302        640: 100% 2/2 [00:01<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.69s/it]\n",
            "                   all         53        205       0.92        0.9      0.931      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      12.6G     0.0449    0.01856          0        286        640: 100% 2/2 [00:01<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.36it/s]\n",
            "                   all         53        205      0.933      0.887      0.912      0.354\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      12.6G    0.04489    0.01842          0        277        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         53        205      0.933      0.889      0.929      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      12.6G    0.04545    0.01861          0        322        640: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         53        205      0.929      0.894      0.938      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      12.6G    0.04674    0.02178          0        392        640: 100% 2/2 [00:01<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         53        205      0.928      0.885      0.921      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      12.6G     0.0436    0.02005          0        342        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.39s/it]\n",
            "                   all         53        205      0.957      0.888      0.947      0.367\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      12.6G    0.04533    0.01901          0        302        640: 100% 2/2 [00:01<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.73s/it]\n",
            "                   all         53        205       0.94      0.898      0.946      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      12.6G    0.04299    0.02114          0        342        640: 100% 2/2 [00:01<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         53        205       0.96      0.878      0.937      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      12.6G    0.04582    0.01868          0        308        640: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.41it/s]\n",
            "                   all         53        205       0.94      0.898      0.943      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      12.6G    0.04615    0.01911          0        310        640: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "                   all         53        205       0.94      0.902       0.95      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      12.6G    0.04352    0.01675          0        282        640: 100% 2/2 [00:01<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all         53        205      0.939        0.9       0.95      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      12.6G    0.04113    0.02005          0        372        640: 100% 2/2 [00:01<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.54s/it]\n",
            "                   all         53        205      0.944      0.896      0.952      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      12.6G    0.04121     0.0164          0        278        640: 100% 2/2 [00:01<00:00,  1.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.71s/it]\n",
            "                   all         53        205      0.933      0.884      0.927      0.369\n",
            "\n",
            "100 epochs completed in 0.095 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.45it/s]\n",
            "                   all         53        205       0.94      0.898       0.94      0.387\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s on Smear images augmented train_data for 100 epochs\n",
        "!python train.py --img 640 --batch -1 --epochs 100 --data ../class1.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything went well, the confusion matrix (that you can find in YOLOBee/Yolov5/yolov5/runs/train/exp/) should look like this:"
      ],
      "metadata": {
        "id": "CKkefG4RvhCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image # Pour la gestion des images\n",
        "myimg = Image.open(\"/content/YOLOBee/Yolov5/yolov5/runs/train/exp/confusion_matrix.png\")\n",
        "\n",
        "myimg.show()\n"
      ],
      "metadata": {
        "id": "z3VzmKbAyWt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8ungS_pGbNE"
      },
      "source": [
        "Validation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training is complete. Now, the validation step will alllow you to see the quality of your training."
      ],
      "metadata": {
        "id": "Gr7ueBA6Wn9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iSK1Ja7GdNT",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08da93bf-0fd3-430a-a5e0-6ba68b480fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=../class1.yaml, weights=['/content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v7.0-338-gff063284 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLOBee/Yolov5/train_data/labels/val.cache... 53 images, 0 backgrounds, 0 corrupt: 100% 53/53 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:11<00:00,  5.63s/it]\n",
            "                   all         53        205      0.928        0.4      0.426      0.172\n",
            "Speed: 0.3ms pre-process, 21.3ms inference, 42.0ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights /content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt --img 640 --data ../class1.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_X4_GDNHbx0"
      },
      "source": [
        "Detection\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation is finished. You can detect bees on pictures or videos"
      ],
      "metadata": {
        "id": "6Fxz2IkbXOW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "6UDl-4H3gBif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c66f68-fa46-424d-e04b-9675de9497c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOBee/Yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.unpack_archive(\"/content/YOLOBee/Yolov5/framesfordetection.zip\")"
      ],
      "metadata": {
        "id": "zdBl0hGPbh6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuL2GQATH-4k",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a41ea5-128d-403b-f184-39db9e3d31c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt'], source=/content/YOLOBee/Yolov5/framesfordetection, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-338-gff063284 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "image 1/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0016.jpg: 384x640 3 bees, 48.0ms\n",
            "image 2/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0016_1.jpg: 384x640 1 bee, 7.5ms\n",
            "image 3/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0017.jpg: 384x640 3 bees, 7.5ms\n",
            "image 4/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0018.jpg: 384x640 4 bees, 7.5ms\n",
            "image 5/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0019.jpg: 384x640 2 bees, 7.5ms\n",
            "image 6/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0019_1.jpg: 384x640 (no detections), 7.5ms\n",
            "image 7/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0020.jpg: 384x640 2 bees, 7.5ms\n",
            "image 8/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0020_1.jpg: 384x640 1 bee, 10.9ms\n",
            "image 9/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0021.jpg: 384x640 3 bees, 7.5ms\n",
            "image 10/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0021_1.jpg: 384x640 1 bee, 7.5ms\n",
            "image 11/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0022.jpg: 384x640 3 bees, 7.5ms\n",
            "image 12/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_0022_1.jpg: 384x640 1 bee, 7.5ms\n",
            "image 13/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0008.jpg: 384x640 5 bees, 7.5ms\n",
            "image 14/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0009.jpg: 384x640 6 bees, 9.7ms\n",
            "image 15/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0010.jpg: 384x640 6 bees, 7.5ms\n",
            "image 16/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0011.jpg: 384x640 5 bees, 7.6ms\n",
            "image 17/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0012.jpg: 384x640 6 bees, 7.5ms\n",
            "image 18/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0013.jpg: 384x640 6 bees, 7.5ms\n",
            "image 19/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0014.jpg: 384x640 6 bees, 8.1ms\n",
            "image 20/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0015.jpg: 384x640 6 bees, 7.6ms\n",
            "image 21/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0016.jpg: 384x640 5 bees, 7.5ms\n",
            "image 22/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0017.jpg: 384x640 5 bees, 7.6ms\n",
            "image 23/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0018.jpg: 384x640 5 bees, 7.5ms\n",
            "image 24/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0019.jpg: 384x640 4 bees, 7.5ms\n",
            "image 25/25 /content/YOLOBee/Yolov5/framesfordetection/Copie de frame_2_0020.jpg: 384x640 6 bees, 7.5ms\n",
            "Speed: 0.5ms pre-process, 9.4ms inference, 24.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp\u001b[0m\n",
            "24 labels saved to yolov5/runs/detect/exp/labels\n"
          ]
        }
      ],
      "source": [
        "!python yolov5/detect.py --weights /content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt --img 640 --source '/content/YOLOBee/Yolov5/framesfordetection' --save-txt --save-conf\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO03ifdnxhPIRnYDLMh4Gds",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}