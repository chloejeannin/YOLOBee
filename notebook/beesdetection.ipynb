[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chloejeannin/YOLOBee/notebook/beesdetection.ipynb)

{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction:\n",
        "This program will train a neural network to recognize bees on videos or pictures.\n"
      ],
      "metadata": {
        "id": "BXW5_RP9I40n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First connect to google drive and clone the YOLOBee repositary"
      ],
      "metadata": {
        "id": "oQP9-I6f3HiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "CAbBPQVjuhg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFEmFd881JmB",
        "outputId": "07f9e4c5-4bda-435f-b80b-5e5536369a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q1VyVG3grEW",
        "outputId": "d8a5965b-28ea-4ef7-eec5-2fc0998ece5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOBee'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 187 (delta 40), reused 16 (delta 16), pack-reused 137\u001b[K\n",
            "Receiving objects: 100% (187/187), 74.61 MiB | 38.68 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chloejeannin/YOLOBee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEWzJcuXHuOc",
        "outputId": "9790df56-7c0b-424b-e16e-a05ca7af57e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOBee/Yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd YOLOBee/Yolov5/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.unpack_archive(\"frames_04+frames_2.zip\")"
      ],
      "metadata": {
        "id": "1XDATk8vexcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0vbqOeTFo-7"
      },
      "source": [
        "Augmentation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The augmentation can allow the algorithm to train on more data that it has. It will create pictures, based on the image of your dataset. The images will be  transformed by different ways. In this case, they will undergo 6 modifications, an Horizontal and vertical Flip, an RandomSizedBBoxSafeCrop, they will be Transpose, Rotate90 and ShiftScaleRotate."
      ],
      "metadata": {
        "id": "quEOuYzI3wUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BftPVP1bkHHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5549f01a-8463-40ee-e038-3ad27ff9f30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SciAugment'...\n",
            "remote: Enumerating objects: 280, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 280 (delta 105), reused 138 (delta 64), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (280/280), 1.32 MiB | 21.38 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/martinschatz-cz/SciAugment.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "875dyFkrkKSf",
        "outputId": "e853b285-50f9-4e3d-f610-fc738a9cdd82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting git+https://github.com/albu/albumentations (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Cloning https://github.com/albu/albumentations to /tmp/pip-req-build-z314uygm\n",
            "  Running command git version\n",
            "  git version 2.34.1\n",
            "  Running command git clone --filter=blob:none https://github.com/albu/albumentations /tmp/pip-req-build-z314uygm\n",
            "  Cloning into '/tmp/pip-req-build-z314uygm'...\n",
            "  Running command git rev-parse HEAD\n",
            "  dae9bd6ca81a089d9d07410eec06eb5c10ebd28d\n",
            "  Resolved https://github.com/albu/albumentations to commit dae9bd6ca81a089d9d07410eec06eb5c10ebd28d\n",
            "  Running command git rev-parse HEAD\n",
            "  dae9bd6ca81a089d9d07410eec06eb5c10ebd28d\n",
            "  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting setuptools\n",
            "    Using cached setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "  Collecting wheel\n",
            "    Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "  Installing collected packages: wheel, setuptools\n",
            "    Creating /tmp/pip-build-env-44xapp3j/overlay/local/bin\n",
            "    changing mode of /tmp/pip-build-env-44xapp3j/overlay/local/bin/wheel to 755\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "  Successfully installed setuptools-70.2.0 wheel-0.43.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  <string>:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  running egg_info\n",
            "  creating albumentations.egg-info\n",
            "  writing albumentations.egg-info/PKG-INFO\n",
            "  writing dependency_links to albumentations.egg-info/dependency_links.txt\n",
            "  writing requirements to albumentations.egg-info/requires.txt\n",
            "  writing top-level names to albumentations.egg-info/top_level.txt\n",
            "  writing manifest file 'albumentations.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'albumentations.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  no previously-included directories found matching 'docs/_build'\n",
            "  warning: no previously-included files matching 'docs/augs_overview/*/images/*.jpg' found anywhere in distribution\n",
            "  warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'albumentations.egg-info/SOURCES.txt'\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  <string>:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  running dist_info\n",
            "  creating /tmp/pip-modern-metadata-gamqh261/albumentations.egg-info\n",
            "  writing /tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  no previously-included directories found matching 'docs/_build'\n",
            "  warning: no previously-included files matching 'docs/augs_overview/*/images/*.jpg' found anywhere in distribution\n",
            "  warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-modern-metadata-gamqh261/albumentations.egg-info/SOURCES.txt'\n",
            "  creating '/tmp/pip-modern-metadata-gamqh261/albumentations-1.4.10.dist-info'\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python-headless>=3.4.18.65 in /usr/local/lib/python3.10/dist-packages (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 2)) (4.10.0.84)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (1.11.4)\n",
            "Collecting scikit-image>=0.21.0 (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (4.12.2)\n",
            "Collecting scikit-learn>=1.3.2 (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2.8.0)\n",
            "Collecting albucore>=0.0.11 (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading albucore-0.0.12-py3-none-any.whl (8.4 kB)\n",
            "Collecting eval-type-backport (from albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1))\n",
            "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.11->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2.20.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (3.3)\n",
            "Collecting imageio (from imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3))\n",
            "  Downloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (2024.6.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r /content/YOLOBee/Yolov5/SciAugment/requirements.txt (line 3)) (2.8.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Running command Building wheel for albumentations (pyproject.toml)\n",
            "  <string>:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/albumentations\n",
            "  copying albumentations/check_version.py -> build/lib/albumentations\n",
            "  copying albumentations/__init__.py -> build/lib/albumentations\n",
            "  copying albumentations/random_utils.py -> build/lib/albumentations\n",
            "  copying albumentations/_version.py -> build/lib/albumentations\n",
            "  creating build/lib/albumentations/core\n",
            "  copying albumentations/core/transforms_interface.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/pydantic.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/utils.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/types.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/keypoints_utils.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/validation.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/__init__.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/hub_mixin.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/serialization.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/composition.py -> build/lib/albumentations/core\n",
            "  copying albumentations/core/bbox_utils.py -> build/lib/albumentations/core\n",
            "  creating build/lib/albumentations/augmentations\n",
            "  copying albumentations/augmentations/domain_adaptation_functional.py -> build/lib/albumentations/augmentations\n",
            "  copying albumentations/augmentations/domain_adaptation.py -> build/lib/albumentations/augmentations\n",
            "  copying albumentations/augmentations/functional.py -> build/lib/albumentations/augmentations\n",
            "  copying albumentations/augmentations/utils.py -> build/lib/albumentations/augmentations\n",
            "  copying albumentations/augmentations/__init__.py -> build/lib/albumentations/augmentations\n",
            "  copying albumentations/augmentations/transforms.py -> build/lib/albumentations/augmentations\n",
            "  creating build/lib/albumentations/pytorch\n",
            "  copying albumentations/pytorch/__init__.py -> build/lib/albumentations/pytorch\n",
            "  copying albumentations/pytorch/transforms.py -> build/lib/albumentations/pytorch\n",
            "  creating build/lib/albumentations/augmentations/blur\n",
            "  copying albumentations/augmentations/blur/functional.py -> build/lib/albumentations/augmentations/blur\n",
            "  copying albumentations/augmentations/blur/__init__.py -> build/lib/albumentations/augmentations/blur\n",
            "  copying albumentations/augmentations/blur/transforms.py -> build/lib/albumentations/augmentations/blur\n",
            "  creating build/lib/albumentations/augmentations/crops\n",
            "  copying albumentations/augmentations/crops/functional.py -> build/lib/albumentations/augmentations/crops\n",
            "  copying albumentations/augmentations/crops/__init__.py -> build/lib/albumentations/augmentations/crops\n",
            "  copying albumentations/augmentations/crops/transforms.py -> build/lib/albumentations/augmentations/crops\n",
            "  creating build/lib/albumentations/augmentations/mixing\n",
            "  copying albumentations/augmentations/mixing/functional.py -> build/lib/albumentations/augmentations/mixing\n",
            "  copying albumentations/augmentations/mixing/__init__.py -> build/lib/albumentations/augmentations/mixing\n",
            "  copying albumentations/augmentations/mixing/transforms.py -> build/lib/albumentations/augmentations/mixing\n",
            "  creating build/lib/albumentations/augmentations/geometric\n",
            "  copying albumentations/augmentations/geometric/functional.py -> build/lib/albumentations/augmentations/geometric\n",
            "  copying albumentations/augmentations/geometric/rotate.py -> build/lib/albumentations/augmentations/geometric\n",
            "  copying albumentations/augmentations/geometric/__init__.py -> build/lib/albumentations/augmentations/geometric\n",
            "  copying albumentations/augmentations/geometric/transforms.py -> build/lib/albumentations/augmentations/geometric\n",
            "  copying albumentations/augmentations/geometric/resize.py -> build/lib/albumentations/augmentations/geometric\n",
            "  creating build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/functional.py -> build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/__init__.py -> build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/grid_dropout.py -> build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/channel_dropout.py -> build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/coarse_dropout.py -> build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/mask_dropout.py -> build/lib/albumentations/augmentations/dropout\n",
            "  copying albumentations/augmentations/dropout/xy_masking.py -> build/lib/albumentations/augmentations/dropout\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations\n",
            "  copying build/lib/albumentations/check_version.py -> build/bdist.linux-x86_64/wheel/albumentations\n",
            "  copying build/lib/albumentations/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations\n",
            "  copying build/lib/albumentations/random_utils.py -> build/bdist.linux-x86_64/wheel/albumentations\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/transforms_interface.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/pydantic.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/utils.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/types.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/keypoints_utils.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/validation.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/hub_mixin.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/serialization.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/composition.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/core/bbox_utils.py -> build/bdist.linux-x86_64/wheel/albumentations/core\n",
            "  copying build/lib/albumentations/_version.py -> build/bdist.linux-x86_64/wheel/albumentations\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  copying build/lib/albumentations/augmentations/domain_adaptation_functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  copying build/lib/albumentations/augmentations/domain_adaptation.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  copying build/lib/albumentations/augmentations/functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  copying build/lib/albumentations/augmentations/utils.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  copying build/lib/albumentations/augmentations/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/augmentations/blur\n",
            "  copying build/lib/albumentations/augmentations/blur/functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/blur\n",
            "  copying build/lib/albumentations/augmentations/blur/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/blur\n",
            "  copying build/lib/albumentations/augmentations/blur/transforms.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/blur\n",
            "  copying build/lib/albumentations/augmentations/transforms.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/augmentations/crops\n",
            "  copying build/lib/albumentations/augmentations/crops/functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/crops\n",
            "  copying build/lib/albumentations/augmentations/crops/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/crops\n",
            "  copying build/lib/albumentations/augmentations/crops/transforms.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/crops\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/augmentations/mixing\n",
            "  copying build/lib/albumentations/augmentations/mixing/functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/mixing\n",
            "  copying build/lib/albumentations/augmentations/mixing/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/mixing\n",
            "  copying build/lib/albumentations/augmentations/mixing/transforms.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/mixing\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/augmentations/geometric\n",
            "  copying build/lib/albumentations/augmentations/geometric/functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/geometric\n",
            "  copying build/lib/albumentations/augmentations/geometric/rotate.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/geometric\n",
            "  copying build/lib/albumentations/augmentations/geometric/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/geometric\n",
            "  copying build/lib/albumentations/augmentations/geometric/transforms.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/geometric\n",
            "  copying build/lib/albumentations/augmentations/geometric/resize.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/geometric\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/functional.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/grid_dropout.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/channel_dropout.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/coarse_dropout.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/mask_dropout.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  copying build/lib/albumentations/augmentations/dropout/xy_masking.py -> build/bdist.linux-x86_64/wheel/albumentations/augmentations/dropout\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations/pytorch\n",
            "  copying build/lib/albumentations/pytorch/__init__.py -> build/bdist.linux-x86_64/wheel/albumentations/pytorch\n",
            "  copying build/lib/albumentations/pytorch/transforms.py -> build/bdist.linux-x86_64/wheel/albumentations/pytorch\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing albumentations.egg-info/PKG-INFO\n",
            "  writing dependency_links to albumentations.egg-info/dependency_links.txt\n",
            "  writing requirements to albumentations.egg-info/requires.txt\n",
            "  writing top-level names to albumentations.egg-info/top_level.txt\n",
            "  reading manifest file 'albumentations.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  no previously-included directories found matching 'docs/_build'\n",
            "  warning: no previously-included files matching 'docs/augs_overview/*/images/*.jpg' found anywhere in distribution\n",
            "  warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'albumentations.egg-info/SOURCES.txt'\n",
            "  Copying albumentations.egg-info to build/bdist.linux-x86_64/wheel/albumentations-1.4.10-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/albumentations-1.4.10.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-1fb0vcbd/.tmp-gbq9ncb5/albumentations-1.4.10-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'albumentations/__init__.py'\n",
            "  adding 'albumentations/_version.py'\n",
            "  adding 'albumentations/check_version.py'\n",
            "  adding 'albumentations/random_utils.py'\n",
            "  adding 'albumentations/augmentations/__init__.py'\n",
            "  adding 'albumentations/augmentations/domain_adaptation.py'\n",
            "  adding 'albumentations/augmentations/domain_adaptation_functional.py'\n",
            "  adding 'albumentations/augmentations/functional.py'\n",
            "  adding 'albumentations/augmentations/transforms.py'\n",
            "  adding 'albumentations/augmentations/utils.py'\n",
            "  adding 'albumentations/augmentations/blur/__init__.py'\n",
            "  adding 'albumentations/augmentations/blur/functional.py'\n",
            "  adding 'albumentations/augmentations/blur/transforms.py'\n",
            "  adding 'albumentations/augmentations/crops/__init__.py'\n",
            "  adding 'albumentations/augmentations/crops/functional.py'\n",
            "  adding 'albumentations/augmentations/crops/transforms.py'\n",
            "  adding 'albumentations/augmentations/dropout/__init__.py'\n",
            "  adding 'albumentations/augmentations/dropout/channel_dropout.py'\n",
            "  adding 'albumentations/augmentations/dropout/coarse_dropout.py'\n",
            "  adding 'albumentations/augmentations/dropout/functional.py'\n",
            "  adding 'albumentations/augmentations/dropout/grid_dropout.py'\n",
            "  adding 'albumentations/augmentations/dropout/mask_dropout.py'\n",
            "  adding 'albumentations/augmentations/dropout/xy_masking.py'\n",
            "  adding 'albumentations/augmentations/geometric/__init__.py'\n",
            "  adding 'albumentations/augmentations/geometric/functional.py'\n",
            "  adding 'albumentations/augmentations/geometric/resize.py'\n",
            "  adding 'albumentations/augmentations/geometric/rotate.py'\n",
            "  adding 'albumentations/augmentations/geometric/transforms.py'\n",
            "  adding 'albumentations/augmentations/mixing/__init__.py'\n",
            "  adding 'albumentations/augmentations/mixing/functional.py'\n",
            "  adding 'albumentations/augmentations/mixing/transforms.py'\n",
            "  adding 'albumentations/core/__init__.py'\n",
            "  adding 'albumentations/core/bbox_utils.py'\n",
            "  adding 'albumentations/core/composition.py'\n",
            "  adding 'albumentations/core/hub_mixin.py'\n",
            "  adding 'albumentations/core/keypoints_utils.py'\n",
            "  adding 'albumentations/core/pydantic.py'\n",
            "  adding 'albumentations/core/serialization.py'\n",
            "  adding 'albumentations/core/transforms_interface.py'\n",
            "  adding 'albumentations/core/types.py'\n",
            "  adding 'albumentations/core/utils.py'\n",
            "  adding 'albumentations/core/validation.py'\n",
            "  adding 'albumentations/pytorch/__init__.py'\n",
            "  adding 'albumentations/pytorch/transforms.py'\n",
            "  adding 'albumentations-1.4.10.dist-info/LICENSE'\n",
            "  adding 'albumentations-1.4.10.dist-info/METADATA'\n",
            "  adding 'albumentations-1.4.10.dist-info/WHEEL'\n",
            "  adding 'albumentations-1.4.10.dist-info/top_level.txt'\n",
            "  adding 'albumentations-1.4.10.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for albumentations (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-1.4.10-py3-none-any.whl size=165202 sha256=f07e096b5c5b7080a4f21d955764d5f74d4e23199311b6a14ff776eae2b21f1e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i5qd3pef/wheels/3c/df/16/b3d0d64428c9f25b1ab03989a2e574546d3336647946d31e56\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imageio, eval-type-backport, scikit-learn, scikit-image, albucore, albumentations\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Removing file or directory /usr/local/bin/imageio_download_bin\n",
            "      Removing file or directory /usr/local/bin/imageio_remove_bin\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/imageio-2.31.6.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/imageio/\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "  changing mode of /usr/local/bin/imageio_download_bin to 755\n",
            "  changing mode of /usr/local/bin/imageio_remove_bin to 755\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_learn-1.2.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_learn.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/sklearn/\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Removing file or directory /usr/local/bin/skivi\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/doc/ext/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_image-0.19.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scikit_image.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/skimage/\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.3.1\n",
            "    Uninstalling albumentations-1.3.1:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/albumentations-1.3.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/albumentations/\n",
            "      Successfully uninstalled albumentations-1.3.1\n",
            "Successfully installed albucore-0.0.12 albumentations-1.4.10 eval-type-backport-0.2.0 imageio-2.34.2 scikit-image-0.24.0 scikit-learn-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/YOLOBee/Yolov5/SciAugment/requirements.txt -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lTp8RI39YosQ"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# SciAug_tools\n",
        "import copy\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from shutil import rmtree\n",
        "from sys import stdout\n",
        "from xml.dom import minidom\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "\n",
        "class SciAugment:\n",
        "    version = \"0.2.0\"\n",
        "    source = \"https://github.com/martinschatz-cz/SciAugment\"\n",
        "    author = \"Martin Schätz\"\n",
        "    aug_type = \"\"\n",
        "    augment = []\n",
        "    channel_augment = []\n",
        "    aug_dict = {\n",
        "        -1: \"no augmentation\",\n",
        "        0: \"HorizontalFlip(p=1)\",\n",
        "        1: \"RandomBrightnessContrast(contrast_limit=0.2,p=1)\",\n",
        "        2: \"MultiplicativeNoise(multiplier=0.5, p=1)\",\n",
        "        3: \"RandomSizedBBoxSafeCrop(250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\",\n",
        "        4: \"Blur(blur_limit=(10, 10), p=0)\",\n",
        "        5: \"Transpose(1)\",\n",
        "        6: \"RandomRotate90(p=1)\",\n",
        "        7: \"ShiftScaleRotate(p=1)\",\n",
        "        8: \"VerticalFlip(p=1)\",\n",
        "        9: \"RandomBrightnessContrast(brightness_limit=0.2,p=1)\",\n",
        "    }\n",
        "\n",
        "    aug_channel_dict = {\n",
        "        -1: \"no augmentation\",\n",
        "        0: \"RandomBrightnessContrast(contrast_limit=0.2,p=1)\",\n",
        "        1: \"MultiplicativeNoise(multiplier=0.5, p=1)\",\n",
        "        2: \"Blur(blur_limit=(10, 10), p=0)\",\n",
        "        3: \"RandomBrightnessContrast(brightness_limit=0.2,p=1)\",\n",
        "        4: \"Superpixels (p_replace=0.1, n_segments=20, max_size=64, interpolation=1, p=1)\",\n",
        "        5: \"GaussNoise (var_limit=(10.0, 50.0), mean=0, p=1)\",\n",
        "    }\n",
        "\n",
        "    #######general functions###########\n",
        "    def __new__(cls, *args, **kwargs):\n",
        "        print(\"New instance of SciAugment.\")\n",
        "        return super().__new__(cls)\n",
        "\n",
        "    def __init__(self, aug_type: str = \"Default\", channel_aug: bool = False):\n",
        "        self.augmet_type = aug_type\n",
        "        print(\"Selected augmentation type: {}\".format(self.augmet_type))\n",
        "        if aug_type == \"Default\":\n",
        "            self.augment = [-1, 0, 3, 5, 6, 7, 8]\n",
        "            if channel_aug:\n",
        "                self.channel_augment = range(-1, 5, 1)\n",
        "\n",
        "        if aug_type == \"fluorescece_microscopy\":\n",
        "            self.augment = range(-1, 9, 1)\n",
        "            if channel_aug:\n",
        "                self.channel_augment = [-1, 1, 2, 3, 4, 5]\n",
        "\n",
        "        if aug_type == \"all\":\n",
        "            self.augment = range(-1, 9, 1)\n",
        "            if channel_aug:\n",
        "                self.channel_augment = range(-1, 5, 1)\n",
        "\n",
        "        if aug_type == \"no_augment\":\n",
        "            self.augment = [-1]\n",
        "            print(\n",
        "                \"No augment setting will only divide images and labels to train_data folder.\"\n",
        "            )\n",
        "            self.channel_augment = []\n",
        "\n",
        "        print(\"\\n\")\n",
        "        self.explain()\n",
        "\n",
        "    def explain(self):\n",
        "        print(\"Version: {}\".format(self.version))\n",
        "        print(\"\\n\")\n",
        "        print(\"Selected augmentation:\")\n",
        "        for aug in self.augment:\n",
        "            print(self.aug_dict[aug])\n",
        "\n",
        "        if self.channel_augment:\n",
        "            print(\"\\n\")\n",
        "            print(\"Selected channel wise augmentation:\")\n",
        "            for ch_aug in self.channel_augment:\n",
        "                print(self.aug_channel_dict[ch_aug])\n",
        "\n",
        "    def info(self):\n",
        "        print(\"Version: {}\".format(self.version))\n",
        "        print(\"\\n\")\n",
        "        print(\"Selected augmentation:\")\n",
        "        for aug in self.augment:\n",
        "            print(self.aug_dict[aug])\n",
        "\n",
        "        if self.channel_augment:\n",
        "            print(\"\\n\")\n",
        "            print(\"Selected channel wise augmentation:\")\n",
        "            for ch_aug in self.channel_augment:\n",
        "                print(self.aug_channel_dict[ch_aug])\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "        print(\"Source: {}\".format(self.source))\n",
        "        print(\"Author: {}\".format(self.author))\n",
        "\n",
        "    def read_image(self, images_path: str, filename: str):\n",
        "        \"\"\"\n",
        "        Uses OpenCV to read RGB images\n",
        "        :param images_path (str):\n",
        "        :param filename (str):\n",
        "        :return: RGB image\n",
        "        \"\"\"\n",
        "\n",
        "        # OpenCV uses BGR channels\n",
        "        img = cv2.imread(images_path + filename)\n",
        "        return img\n",
        "\n",
        "    def read_image_unchanged(self, images_path: str, filename: str):\n",
        "        \"\"\"\n",
        "        Uses OpenCV to read RGBA or 4 channel (maximum) images\n",
        "        :param images_path (str):\n",
        "        :param filename (str):\n",
        "        :return: RGB image\n",
        "        \"\"\"\n",
        "        # https://learnopencv.com/read-an-image-in-opencv-python-cpp/\n",
        "        # OpenCV uses BGR channels\n",
        "        img = cv2.imread(\n",
        "            images_path + filename, cv2.IMREAD_UNCHANGED | cv2.IMREAD_ANYDEPTH\n",
        "        )\n",
        "        return img\n",
        "\n",
        "    def read_yolo(self, filename: str) -> float:\n",
        "        \"\"\"\n",
        "        Reads YOLO type of object anotation for albumentation to read\n",
        "        :param filename (str):\n",
        "        :return yolo_coords:\n",
        "        \"\"\"\n",
        "        yolo_coords = []\n",
        "        with open(filename, \"r\") as fname:\n",
        "            for yolo in fname:\n",
        "                x = yolo.strip().split(\" \")\n",
        "                x.append(x[0])\n",
        "                x.pop(0)\n",
        "                x[0] = float(x[0])\n",
        "                x[1] = float(x[1])\n",
        "                x[2] = float(x[2])\n",
        "                x[3] = float(x[3])\n",
        "                # print(x)\n",
        "                yolo_coords.append(x)\n",
        "        return yolo_coords\n",
        "\n",
        "    def write_yolo(self, coords: float, name: str):\n",
        "        \"\"\"\n",
        "        Write YOLO type object coordinates to txt file\n",
        "        :param coords (float): list of coordinates\n",
        "        :param name (str): name of file to write to\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        with open(name + \".txt\", \"w\") as f:\n",
        "            for x in coords:\n",
        "                f.write(\"%s %s %s %s %s \\n\" % (x[-1], x[0], x[1], x[2], x[3]))\n",
        "        return 0\n",
        "\n",
        "    def create_train_data_folder(self):\n",
        "        try:\n",
        "            dir = \"train_data\"\n",
        "            if os.path.exists(dir):\n",
        "                print(\"Train_data folder already exists!\")  # , and will be removed.')\n",
        "                return 1\n",
        "                # shutil.rmtree(dir)\n",
        "            else:\n",
        "                os.mkdir(dir)\n",
        "\n",
        "            # info_path = dir + '/info.txt'\n",
        "            # with open(info_path, 'w') as f:\n",
        "            #   f.writelines(self.info())\n",
        "\n",
        "            dir_image_train = \"train_data/images/train\"\n",
        "            dir_image_val = \"train_data/images/val\"\n",
        "            dir_label_train = \"train_data/labels/train\"\n",
        "            dir_label_val = \"train_data/labels/val\"\n",
        "\n",
        "            os.mkdir(\"train_data/images\")\n",
        "            os.mkdir(\"train_data/labels\")\n",
        "            os.mkdir(dir_image_train)\n",
        "            os.mkdir(dir_image_val)\n",
        "            os.mkdir(dir_label_train)\n",
        "            os.mkdir(dir_label_val)\n",
        "\n",
        "            return 0\n",
        "        except:\n",
        "            print(\"Error while creating new train_data folder structure!\")\n",
        "            return 1\n",
        "\n",
        "    #########transform functions########\n",
        "    def get_transform(loop: int):\n",
        "        \"\"\"\n",
        "      !!!OLD FUNCTION, DO NOT USE!!!\n",
        "              Generating image an label augmentation for YOLO with name tag of augmentations.\n",
        "\n",
        "              :param loop (int): Number of augmentation from 0 to 8\n",
        "\n",
        "              :return:\n",
        "              A: transform function with BboxParams set for Yolo\n",
        "              name (string): Name where relevant to position is bit length 11 for:\n",
        "                1:Shift\n",
        "                2:Scale\n",
        "                3:Rotate\n",
        "                4:VerticalFlip\n",
        "                5:HorizontalFlip\n",
        "                6:RandomContrast\n",
        "                7:MultiplicativeNoise(multiplier=0.5, p=1)\n",
        "                8:RandomSizedBBoxSafeCrop (250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\n",
        "                9:Blur(blur_limit=(10, 10), p=0)\n",
        "                10:Transpose\n",
        "                11:RandomRotate90\n",
        "                12:RandomBrightness\n",
        "        \"\"\"\n",
        "        if loop == 0:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    A.HorizontalFlip(p=1),\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00001000000\"\n",
        "        elif loop == 1:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    A.RandomBrightnessContrast(p=1),\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000100000\"\n",
        "        elif loop == 2:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    A.HorizontalFlip(p=0),\n",
        "                    A.MultiplicativeNoise(multiplier=0.5, p=1),\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000010000\"\n",
        "        elif loop == 3:\n",
        "            transform = A.Compose(\n",
        "                [\n",
        "                    # A.CenterCrop(width=250, height=250, p=1)\n",
        "                    A.RandomSizedBBoxSafeCrop(\n",
        "                        250, 250, erosion_rate=0.0, interpolation=1, p=1.0\n",
        "                    )\n",
        "                ],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000001000\"\n",
        "        elif loop == 4:\n",
        "            transform = A.Compose(\n",
        "                [A.Blur(blur_limit=(10, 10), p=1)],\n",
        "                bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "            )\n",
        "            name = \"00000000100\"\n",
        "        elif loop == 5:\n",
        "            transform = A.Compose(\n",
        "                [A.Transpose(p=11)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"00000000010\"\n",
        "        elif loop == 6:\n",
        "            transform = A.Compose(\n",
        "                [A.RandomRotate90(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"00000000001\"\n",
        "        elif loop == 7:\n",
        "            transform = A.Compose(\n",
        "                [A.ShiftScaleRotate(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"11100000000\"\n",
        "        elif loop == 8:\n",
        "            transform = A.Compose(\n",
        "                [A.VerticalFlip(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "            )\n",
        "            name = \"00010000000\"\n",
        "        # elif loop == 7:\n",
        "        #     transform = A.Compose([\n",
        "        #         A.ImageCompression(quality_lower=0, quality_upper=1, p=0.2)\n",
        "        #     ], bbox_params=A.BboxParams(format='yolo'))\n",
        "        # elif loop == 8:\n",
        "        #     transform = A.Compose([\n",
        "        #         A.CoarseDropout(max_holes=50, max_height=40,\n",
        "        #                  max_width=40, fill_value=128, p=0)\n",
        "        #     ], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "        # transform = A.Compose([\n",
        "        #         A.HorizontalFlip(p=1),\n",
        "        #     ], bbox_params=A.BboxParams(format='yolo'))\n",
        "\n",
        "        return transform, name\n",
        "\n",
        "    def _h_flip():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.HorizontalFlip(p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000010000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_contrast():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.RandomBrightnessContrast(contrast_limit=0.2, p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000001000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _multi_noise():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.HorizontalFlip(p=0),\n",
        "                A.MultiplicativeNoise(multiplier=0.5, p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000000100000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_size_crop():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                # A.CenterCrop(width=250, height=250, p=1)\n",
        "                A.RandomSizedBBoxSafeCrop(\n",
        "                    250, 250, erosion_rate=0.0, interpolation=1, p=1.0\n",
        "                )\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000000010000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _im_blur():\n",
        "        transform = A.Compose(\n",
        "            [A.Blur(blur_limit=(10, 10), p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000001000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _im_transpose():\n",
        "        transform = A.Compose(\n",
        "            [A.Transpose(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000000100\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_rotate():\n",
        "        transform = A.Compose(\n",
        "            [A.RandomRotate90(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000000010\"\n",
        "        return transform, name\n",
        "\n",
        "    def _shift_scale_rotate():\n",
        "        transform = A.Compose(\n",
        "            [A.ShiftScaleRotate(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"111000000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _v_flip():\n",
        "        transform = A.Compose(\n",
        "            [A.VerticalFlip(p=1)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000100000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _no_augment():\n",
        "        transform = A.Compose(\n",
        "            [A.VerticalFlip(p=0)], bbox_params=A.BboxParams(format=\"yolo\")\n",
        "        )\n",
        "        name = \"000000000000\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_brightness():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, p=1),\n",
        "            ],\n",
        "            bbox_params=A.BboxParams(format=\"yolo\"),\n",
        "        )\n",
        "        name = \"000000000001\"\n",
        "        return transform, name\n",
        "\n",
        "    # for 16 bit A.ToFloat(max_value=65535.0),\n",
        "    #     \"\"\"\n",
        "    #       1:Shift\n",
        "    #       2:Scale\n",
        "    #       3:Rotate\n",
        "    #       4:VerticalFlip\n",
        "    #       5:HorizontalFlip\n",
        "    #       6:RandomBrightnessContrast\n",
        "    #       7:MultiplicativeNoise(multiplier=0.5, p=1)\n",
        "    #       8:RandomSizedBBoxSafeCrop (250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\n",
        "    #       9:Blur(blur_limit=(10, 10), p=0)\n",
        "    #       10:Transpose\n",
        "    #       11:RandomRotate90\n",
        "    #     \"\"\"\n",
        "\n",
        "    aug_functions = {\n",
        "        -1: _no_augment,\n",
        "        0: _h_flip,\n",
        "        1: _rand_contrast,\n",
        "        2: _multi_noise,\n",
        "        3: _rand_size_crop,\n",
        "        4: _im_blur,\n",
        "        5: _im_transpose,\n",
        "        6: _rand_rotate,\n",
        "        7: _shift_scale_rotate,\n",
        "        8: _v_flip,\n",
        "        9: _rand_brightness,\n",
        "    }\n",
        "\n",
        "    # add functions\n",
        "    def _no_augment_ch():\n",
        "        transform = A.Compose([A.VerticalFlip(p=0)])\n",
        "        name = \"-NA\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_contrast_ch():\n",
        "        transform = A.Compose([A.RandomBrightnessContrast(contrast_limit=0.2, p=1)])\n",
        "        name = \"-RC\"\n",
        "        return transform, name\n",
        "\n",
        "    def _multi_noise_ch():\n",
        "        transform = A.Compose([A.MultiplicativeNoise(multiplier=0.5, p=1)])\n",
        "        name = \"-MN\"\n",
        "        return transform, name\n",
        "\n",
        "    def _im_blur_ch():\n",
        "        transform = A.Compose([A.Blur(blur_limit=(10, 10), p=1)])\n",
        "        name = \"-B\"\n",
        "        return transform, name\n",
        "\n",
        "    def _rand_brightness_ch():\n",
        "        transform = A.Compose([A.RandomBrightnessContrast(brightness_limit=0.2, p=1)])\n",
        "        name = \"-RB\"\n",
        "        return transform, name\n",
        "\n",
        "    def _superpixels_ch():\n",
        "        transform = A.Compose(\n",
        "            [\n",
        "                A.Superpixels(\n",
        "                    p_replace=0.1, n_segments=20, max_size=64, interpolation=1, p=1\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        name = \"-SP\"\n",
        "        return transform, name\n",
        "\n",
        "    def _gauss_noise_ch():\n",
        "        transform = A.Compose([A.GaussNoise(var_limit=(10.0, 50.0), mean=0, p=1)])\n",
        "        name = \"-GN\"\n",
        "        return transform, name\n",
        "\n",
        "    channel_aug_functions = {\n",
        "        -1: _no_augment_ch,\n",
        "        0: _rand_contrast_ch,\n",
        "        1: _multi_noise_ch,\n",
        "        2: _im_blur_ch,\n",
        "        3: _rand_brightness_ch,\n",
        "        4: _superpixels_ch,\n",
        "        5: _gauss_noise_ch,\n",
        "    }\n",
        "\n",
        "    #####apply functions######\n",
        "    def augment_data(\n",
        "        self,\n",
        "        images_path: str,\n",
        "        train: float = 0.7,\n",
        "        image_format: str = \".png\",\n",
        "        output_image_format: str = \".jpg\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Augment input images and YOLO files as defined in get_transform() function and save then in train_dir prepared for training and test/val based on 70/30 rule.\n",
        "        :param images_path (str):\n",
        "        :param train (float): train/val parameter for generating training data set, default 70% train 30% val\n",
        "        :param image_format (str): image format name ('.png' default)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        # dir = 'train_data'\n",
        "\n",
        "        dir_image_train = \"train_data/images/train\"\n",
        "        dir_image_val = \"train_data/images/val\"\n",
        "        dir_label_train = \"train_data/labels/train\"\n",
        "        dir_label_val = \"train_data/labels/val\"\n",
        "\n",
        "        folder_err = self.create_train_data_folder()\n",
        "        if folder_err:\n",
        "            print(\"Please remove existing trin_data folder and try again.\")\n",
        "            return 1\n",
        "\n",
        "        # image_format = \".png\"\n",
        "        # train = 0.7\n",
        "        test = 1 - train\n",
        "        files_to_process = sorted(os.listdir(images_path))\n",
        "        print(\"Num of files: \" + str(len(files_to_process)))\n",
        "\n",
        "        #define empty title, ext, xmlTitle, txtExt\n",
        "        title = 'title'\n",
        "        ext = 'ext'\n",
        "        xmlTitle = 'xmlTitle'\n",
        "        txtExt = 'txtExt'\n",
        "\n",
        "        for filename in files_to_process:\n",
        "            print(\"Processing: \" + filename)\n",
        "\n",
        "            if filename.endswith(image_format.lower()) or filename.endswith(\n",
        "                image_format.upper()\n",
        "            ):\n",
        "                title, ext = os.path.splitext(os.path.basename(filename))\n",
        "                print(images_path)\n",
        "                print(filename)\n",
        "                image = self.read_image(images_path, filename)\n",
        "            if filename.endswith(\".txt\"):\n",
        "                xmlTitle, txtExt = os.path.splitext(os.path.basename(filename))\n",
        "                if xmlTitle == title:\n",
        "                    # bboxes = getCoordinates(filename)\n",
        "                    bboxes = self.read_yolo(images_path + xmlTitle + \".txt\")\n",
        "                    print(images_path + xmlTitle + \".txt\")\n",
        "                    for aug in self.augment:\n",
        "                        img = copy.deepcopy(image)\n",
        "                        transform, name_tag = self.aug_functions[aug]()\n",
        "                        dice = random.uniform(0, 1)\n",
        "                        # try:\n",
        "                        transformed = transform(image=img, bboxes=bboxes)\n",
        "                        transformed_image = transformed[\"image\"]\n",
        "                        transformed_bboxes = transformed[\"bboxes\"]\n",
        "                        name = (\n",
        "                            title\n",
        "                            + \"_\"\n",
        "                            + str(count)\n",
        "                            + \"_\"\n",
        "                            + name_tag\n",
        "                            + output_image_format\n",
        "                        )\n",
        "                        # print(name)\n",
        "                        if dice <= train:\n",
        "                            p_name = dir_image_train + \"/\" + name\n",
        "                        else:\n",
        "                            p_name = dir_image_val + \"/\" + name\n",
        "\n",
        "                        cv2.imwrite(p_name, transformed_image)\n",
        "                        print(\"Writing \" + name)\n",
        "                        # print(transformed_bboxes)\n",
        "                        # writeVoc(transformed_bboxes, count, transformed_image)\n",
        "                        # pTitle='/content/'+dir+'/'+title\n",
        "                        if dice <= train:\n",
        "                            p_title = (\n",
        "                                dir_label_train\n",
        "                                + \"/\"\n",
        "                                + title\n",
        "                                + \"_\"\n",
        "                                + str(count)\n",
        "                                + \"_\"\n",
        "                                + name_tag\n",
        "                            )\n",
        "                        else:\n",
        "                            p_title = (\n",
        "                                dir_label_val\n",
        "                                + \"/\"\n",
        "                                + title\n",
        "                                + \"_\"\n",
        "                                + str(count)\n",
        "                                + \"_\"\n",
        "                                + name_tag\n",
        "                            )\n",
        "\n",
        "                        self.write_yolo(transformed_bboxes, p_title)\n",
        "                        count = count + 1\n",
        "                        # except:\n",
        "                        # print(\"Bounding Box exception!!!\")\n",
        "                        # pass\n",
        "        print(\"Process created {} images\".format(count))\n",
        "\n",
        "    def augment_data_per_channel(\n",
        "        self,\n",
        "        images_path: str,\n",
        "        train: float = 0.7,\n",
        "        image_format: str = \".png\",\n",
        "        output_image_format: str = \".png\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Augment input images and YOLO files as defined in get_transform() function and save then in train_dir prepared for training and test/val based on 70/30 rule.\n",
        "        :param images_path (str):\n",
        "        :param train (float): train/val parameter for generating training data set, default 70% train 30% val\n",
        "        :param image_format (str): image format name ('.png' default)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        # dir = 'train_data'\n",
        "\n",
        "        dir_image_train = \"train_data/images/train\"\n",
        "        dir_image_val = \"train_data/images/val\"\n",
        "        dir_label_train = \"train_data/labels/train\"\n",
        "        dir_label_val = \"train_data/labels/val\"\n",
        "\n",
        "        folder_err = self.create_train_data_folder()\n",
        "        if folder_err:\n",
        "            print(\"Please remove existing trin_data folder and try again.\")\n",
        "            return 1\n",
        "\n",
        "        # image_format = \".png\"\n",
        "        # train = 0.7\n",
        "        test = 1 - train\n",
        "        files_to_process = sorted(os.listdir(images_path))\n",
        "        print(\"Num of files: \" + str(len(files_to_process)))\n",
        "\n",
        "        for filename in files_to_process:\n",
        "            print(\"Processing: \" + filename)\n",
        "\n",
        "            if filename.endswith(image_format.lower()) or filename.endswith(\n",
        "                image_format.upper()\n",
        "            ):\n",
        "                title, ext = os.path.splitext(os.path.basename(filename))\n",
        "                print(images_path)\n",
        "                print(filename)\n",
        "                image = self.read_image_unchanged(images_path, filename)\n",
        "            if filename.endswith(\".txt\"):\n",
        "                xmlTitle, txtExt = os.path.splitext(os.path.basename(filename))\n",
        "                if xmlTitle == title:\n",
        "                    # bboxes = getCoordinates(filename)\n",
        "                    bboxes = self.read_yolo(images_path + xmlTitle + \".txt\")\n",
        "                    print(images_path + xmlTitle + \".txt\")\n",
        "                    for aug in self.augment:\n",
        "                        img = copy.deepcopy(image)\n",
        "                        transform, name_tag = self.aug_functions[aug]()\n",
        "                        dice = random.uniform(0, 1)\n",
        "                        #####apply also channel augmentation#####\n",
        "                        # try:\n",
        "                        transformed = transform(image=img, bboxes=bboxes)\n",
        "                        transformed_image = transformed[\"image\"]\n",
        "                        transformed_bboxes = transformed[\"bboxes\"]\n",
        "\n",
        "                        # go through channel transports\n",
        "                        for ch_aug in self.channel_augment:\n",
        "\n",
        "                            transform_ch, ch_name_tag = self.channel_aug_functions[\n",
        "                                ch_aug\n",
        "                            ]()\n",
        "\n",
        "                            # split channels\n",
        "                            im_split = cv2.split(transformed_image)\n",
        "\n",
        "                            for ch in range(0, len(im_split), 1):\n",
        "                                channel = im_split[ch]\n",
        "\n",
        "                                transformed = transform_ch(image=channel)\n",
        "                                transformed_channel = transformed[\"image\"]\n",
        "\n",
        "                                im_merge = copy.deepcopy(im_split)\n",
        "                                im_merge[ch] = transformed_channel\n",
        "                                merged_transformed = cv2.merge(im_merge)\n",
        "                                name_tag_ch = \"_ch-\" + str(ch + 1) + ch_name_tag\n",
        "                                # print(name_ch)\n",
        "                                # cv2_imshow(merged)\n",
        "                                # save\n",
        "                                name = (\n",
        "                                    title\n",
        "                                    + \"_\"\n",
        "                                    + str(count)\n",
        "                                    + \"_\"\n",
        "                                    + name_tag\n",
        "                                    + name_tag_ch\n",
        "                                )\n",
        "                                # print(name)\n",
        "                                if dice <= train:\n",
        "                                    p_name = (\n",
        "                                        dir_image_train\n",
        "                                        + \"/\"\n",
        "                                        + name\n",
        "                                        + output_image_format\n",
        "                                    )\n",
        "                                else:\n",
        "                                    p_name = (\n",
        "                                        dir_image_val + \"/\" + name + output_image_format\n",
        "                                    )\n",
        "\n",
        "                                cv2.imwrite(p_name, merged_transformed)\n",
        "                                print(\"Writing \" + name)\n",
        "                                # print(transformed_bboxes)\n",
        "                                # writeVoc(transformed_bboxes, count, transformed_image)\n",
        "                                # pTitle='/content/'+dir+'/'+title\n",
        "                                if dice <= train:\n",
        "                                    p_title = dir_label_train + \"/\" + name\n",
        "                                else:\n",
        "                                    p_title = dir_label_val + \"/\" + name\n",
        "\n",
        "                                self.write_yolo(transformed_bboxes, p_title)\n",
        "                                count = count + 1\n",
        "                        # except:\n",
        "                        # print(\"Augmentation exception!!!\")\n",
        "                        # pass\n",
        "        print(\"Process created {} images\".format(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcqbG04kand"
      },
      "outputs": [],
      "source": [
        "from SciAugment.utilities.SciAug_tools import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W482j5sQkdUW"
      },
      "outputs": [],
      "source": [
        "#@markdown Specifie a path to folder with images and YOLO anotations\n",
        "input_images_folder = '/content/YOLOBee/Yolov5/frames_04+frames_2/'  # @param{type: 'string'}\n",
        "input_image_format = '.jpg'  # @param{type: 'string'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM88DVS_kgU2",
        "outputId": "17b6c41a-a39d-4b23-babf-99d7b5b82907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New instance of SciAugment.\n",
            "Selected augmentation type: Default\n",
            "\n",
            "\n",
            "Version: 0.1.0\n",
            "\n",
            "\n",
            "Selected augmentation:\n",
            "HorizontalFlip(p=1)\n",
            "RandomSizedBBoxSafeCrop(250, 250, erosion_rate=0.0, interpolation=1, p=1.0)\n",
            "Transpose(1)\n",
            "RandomRotate90(p=1)\n",
            "ShiftScaleRotate(p=1)\n",
            "VerticalFlip(p=1)\n"
          ]
        }
      ],
      "source": [
        "aug = SciAugment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkj65OgqOIaJ",
        "outputId": "9fb290f1-12bb-4c2d-94b3-d10f80bcf5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FX4HqISWkjKu",
        "outputId": "9bd5d5c7-2389-4426-a96e-cfca2370399d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of files: 54\n",
            "Processing: Copie de frame_0002.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0002.jpg\n",
            "Processing: Copie de frame_0002.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0002.txt\n",
            "Writing Copie de frame_0002_0_00001000000.jpg\n",
            "Writing Copie de frame_0002_1_00000001000.jpg\n",
            "Writing Copie de frame_0002_2_00000000010.jpg\n",
            "Writing Copie de frame_0002_3_00000000001.jpg\n",
            "Writing Copie de frame_0002_4_11100000000.jpg\n",
            "Writing Copie de frame_0002_5_00010000000.jpg\n",
            "Processing: Copie de frame_0003.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0003.jpg\n",
            "Processing: Copie de frame_0003.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0003.txt\n",
            "Writing Copie de frame_0003_6_00001000000.jpg\n",
            "Writing Copie de frame_0003_7_00000001000.jpg\n",
            "Writing Copie de frame_0003_8_00000000010.jpg\n",
            "Writing Copie de frame_0003_9_00000000001.jpg\n",
            "Writing Copie de frame_0003_10_11100000000.jpg\n",
            "Writing Copie de frame_0003_11_00010000000.jpg\n",
            "Processing: Copie de frame_0004.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0004.jpg\n",
            "Processing: Copie de frame_0004.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0004.txt\n",
            "Writing Copie de frame_0004_12_00001000000.jpg\n",
            "Writing Copie de frame_0004_13_00000001000.jpg\n",
            "Writing Copie de frame_0004_14_00000000010.jpg\n",
            "Writing Copie de frame_0004_15_00000000001.jpg\n",
            "Writing Copie de frame_0004_16_11100000000.jpg\n",
            "Writing Copie de frame_0004_17_00010000000.jpg\n",
            "Processing: Copie de frame_0005.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0005.jpg\n",
            "Processing: Copie de frame_0005.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0005.txt\n",
            "Writing Copie de frame_0005_18_00001000000.jpg\n",
            "Writing Copie de frame_0005_19_00000001000.jpg\n",
            "Writing Copie de frame_0005_20_00000000010.jpg\n",
            "Writing Copie de frame_0005_21_00000000001.jpg\n",
            "Writing Copie de frame_0005_22_11100000000.jpg\n",
            "Writing Copie de frame_0005_23_00010000000.jpg\n",
            "Processing: Copie de frame_0006.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0006.jpg\n",
            "Processing: Copie de frame_0006.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0006.txt\n",
            "Writing Copie de frame_0006_24_00001000000.jpg\n",
            "Writing Copie de frame_0006_25_00000001000.jpg\n",
            "Writing Copie de frame_0006_26_00000000010.jpg\n",
            "Writing Copie de frame_0006_27_00000000001.jpg\n",
            "Writing Copie de frame_0006_28_11100000000.jpg\n",
            "Writing Copie de frame_0006_29_00010000000.jpg\n",
            "Processing: Copie de frame_0007.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0007.jpg\n",
            "Processing: Copie de frame_0007.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0007.txt\n",
            "Writing Copie de frame_0007_30_00001000000.jpg\n",
            "Writing Copie de frame_0007_31_00000001000.jpg\n",
            "Writing Copie de frame_0007_32_00000000010.jpg\n",
            "Writing Copie de frame_0007_33_00000000001.jpg\n",
            "Writing Copie de frame_0007_34_11100000000.jpg\n",
            "Writing Copie de frame_0007_35_00010000000.jpg\n",
            "Processing: Copie de frame_0008.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0008.jpg\n",
            "Processing: Copie de frame_0008.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0008.txt\n",
            "Writing Copie de frame_0008_36_00001000000.jpg\n",
            "Writing Copie de frame_0008_37_00000001000.jpg\n",
            "Writing Copie de frame_0008_38_00000000010.jpg\n",
            "Writing Copie de frame_0008_39_00000000001.jpg\n",
            "Writing Copie de frame_0008_40_11100000000.jpg\n",
            "Writing Copie de frame_0008_41_00010000000.jpg\n",
            "Processing: Copie de frame_0009.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0009.jpg\n",
            "Processing: Copie de frame_0009.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0009.txt\n",
            "Writing Copie de frame_0009_42_00001000000.jpg\n",
            "Writing Copie de frame_0009_43_00000001000.jpg\n",
            "Writing Copie de frame_0009_44_00000000010.jpg\n",
            "Writing Copie de frame_0009_45_00000000001.jpg\n",
            "Writing Copie de frame_0009_46_11100000000.jpg\n",
            "Writing Copie de frame_0009_47_00010000000.jpg\n",
            "Processing: Copie de frame_0010.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0010.jpg\n",
            "Processing: Copie de frame_0010.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0010.txt\n",
            "Writing Copie de frame_0010_48_00001000000.jpg\n",
            "Writing Copie de frame_0010_49_00000001000.jpg\n",
            "Writing Copie de frame_0010_50_00000000010.jpg\n",
            "Writing Copie de frame_0010_51_00000000001.jpg\n",
            "Writing Copie de frame_0010_52_11100000000.jpg\n",
            "Writing Copie de frame_0010_53_00010000000.jpg\n",
            "Processing: Copie de frame_0011.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0011.jpg\n",
            "Processing: Copie de frame_0011.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0011.txt\n",
            "Writing Copie de frame_0011_54_00001000000.jpg\n",
            "Writing Copie de frame_0011_55_00000001000.jpg\n",
            "Writing Copie de frame_0011_56_00000000010.jpg\n",
            "Writing Copie de frame_0011_57_00000000001.jpg\n",
            "Writing Copie de frame_0011_58_11100000000.jpg\n",
            "Writing Copie de frame_0011_59_00010000000.jpg\n",
            "Processing: Copie de frame_0012.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0012.jpg\n",
            "Processing: Copie de frame_0012.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0012.txt\n",
            "Writing Copie de frame_0012_60_00001000000.jpg\n",
            "Writing Copie de frame_0012_61_00000001000.jpg\n",
            "Writing Copie de frame_0012_62_00000000010.jpg\n",
            "Writing Copie de frame_0012_63_00000000001.jpg\n",
            "Writing Copie de frame_0012_64_11100000000.jpg\n",
            "Writing Copie de frame_0012_65_00010000000.jpg\n",
            "Processing: Copie de frame_0013.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0013.jpg\n",
            "Processing: Copie de frame_0013.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0013.txt\n",
            "Writing Copie de frame_0013_66_00001000000.jpg\n",
            "Writing Copie de frame_0013_67_00000001000.jpg\n",
            "Writing Copie de frame_0013_68_00000000010.jpg\n",
            "Writing Copie de frame_0013_69_00000000001.jpg\n",
            "Writing Copie de frame_0013_70_11100000000.jpg\n",
            "Writing Copie de frame_0013_71_00010000000.jpg\n",
            "Processing: Copie de frame_0014.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0014.jpg\n",
            "Processing: Copie de frame_0014.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0014.txt\n",
            "Writing Copie de frame_0014_72_00001000000.jpg\n",
            "Writing Copie de frame_0014_73_00000001000.jpg\n",
            "Writing Copie de frame_0014_74_00000000010.jpg\n",
            "Writing Copie de frame_0014_75_00000000001.jpg\n",
            "Writing Copie de frame_0014_76_11100000000.jpg\n",
            "Writing Copie de frame_0014_77_00010000000.jpg\n",
            "Processing: Copie de frame_0015.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0015.jpg\n",
            "Processing: Copie de frame_0015.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0015.txt\n",
            "Writing Copie de frame_0015_78_00001000000.jpg\n",
            "Writing Copie de frame_0015_79_00000001000.jpg\n",
            "Writing Copie de frame_0015_80_00000000010.jpg\n",
            "Writing Copie de frame_0015_81_00000000001.jpg\n",
            "Writing Copie de frame_0015_82_11100000000.jpg\n",
            "Writing Copie de frame_0015_83_00010000000.jpg\n",
            "Processing: Copie de frame_0015_1.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0015_1.jpg\n",
            "Processing: Copie de frame_0015_1.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0015_1.txt\n",
            "Writing Copie de frame_0015_1_84_00001000000.jpg\n",
            "Writing Copie de frame_0015_1_85_00000001000.jpg\n",
            "Writing Copie de frame_0015_1_86_00000000010.jpg\n",
            "Writing Copie de frame_0015_1_87_00000000001.jpg\n",
            "Writing Copie de frame_0015_1_88_11100000000.jpg\n",
            "Writing Copie de frame_0015_1_89_00010000000.jpg\n",
            "Processing: Copie de frame_0030_1 (1).jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_0030_1 (1).jpg\n",
            "Processing: Copie de frame_0030_1 (1).txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_0030_1 (1).txt\n",
            "Writing Copie de frame_0030_1 (1)_90_00001000000.jpg\n",
            "Writing Copie de frame_0030_1 (1)_91_00000001000.jpg\n",
            "Writing Copie de frame_0030_1 (1)_92_00000000010.jpg\n",
            "Writing Copie de frame_0030_1 (1)_93_00000000001.jpg\n",
            "Writing Copie de frame_0030_1 (1)_94_11100000000.jpg\n",
            "Writing Copie de frame_0030_1 (1)_95_00010000000.jpg\n",
            "Processing: Copie de frame_2_0000.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0000.jpg\n",
            "Processing: Copie de frame_2_0000.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0000.txt\n",
            "Writing Copie de frame_2_0000_96_00001000000.jpg\n",
            "Writing Copie de frame_2_0000_97_00000001000.jpg\n",
            "Writing Copie de frame_2_0000_98_00000000010.jpg\n",
            "Writing Copie de frame_2_0000_99_00000000001.jpg\n",
            "Writing Copie de frame_2_0000_100_11100000000.jpg\n",
            "Writing Copie de frame_2_0000_101_00010000000.jpg\n",
            "Processing: Copie de frame_2_0001.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0001.jpg\n",
            "Processing: Copie de frame_2_0001.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0001.txt\n",
            "Writing Copie de frame_2_0001_102_00001000000.jpg\n",
            "Writing Copie de frame_2_0001_103_00000001000.jpg\n",
            "Writing Copie de frame_2_0001_104_00000000010.jpg\n",
            "Writing Copie de frame_2_0001_105_00000000001.jpg\n",
            "Writing Copie de frame_2_0001_106_11100000000.jpg\n",
            "Writing Copie de frame_2_0001_107_00010000000.jpg\n",
            "Processing: Copie de frame_2_0021.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0021.jpg\n",
            "Processing: Copie de frame_2_0021.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0021.txt\n",
            "Writing Copie de frame_2_0021_108_00001000000.jpg\n",
            "Writing Copie de frame_2_0021_109_00000001000.jpg\n",
            "Writing Copie de frame_2_0021_110_00000000010.jpg\n",
            "Writing Copie de frame_2_0021_111_00000000001.jpg\n",
            "Writing Copie de frame_2_0021_112_11100000000.jpg\n",
            "Writing Copie de frame_2_0021_113_00010000000.jpg\n",
            "Processing: Copie de frame_2_0022.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0022.jpg\n",
            "Processing: Copie de frame_2_0022.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0022.txt\n",
            "Writing Copie de frame_2_0022_114_00001000000.jpg\n",
            "Writing Copie de frame_2_0022_115_00000001000.jpg\n",
            "Writing Copie de frame_2_0022_116_00000000010.jpg\n",
            "Writing Copie de frame_2_0022_117_00000000001.jpg\n",
            "Writing Copie de frame_2_0022_118_11100000000.jpg\n",
            "Writing Copie de frame_2_0022_119_00010000000.jpg\n",
            "Processing: Copie de frame_2_0023.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0023.jpg\n",
            "Processing: Copie de frame_2_0023.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0023.txt\n",
            "Writing Copie de frame_2_0023_120_00001000000.jpg\n",
            "Writing Copie de frame_2_0023_121_00000001000.jpg\n",
            "Writing Copie de frame_2_0023_122_00000000010.jpg\n",
            "Writing Copie de frame_2_0023_123_00000000001.jpg\n",
            "Writing Copie de frame_2_0023_124_11100000000.jpg\n",
            "Writing Copie de frame_2_0023_125_00010000000.jpg\n",
            "Processing: Copie de frame_2_0024.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0024.jpg\n",
            "Processing: Copie de frame_2_0024.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0024.txt\n",
            "Writing Copie de frame_2_0024_126_00001000000.jpg\n",
            "Writing Copie de frame_2_0024_127_00000001000.jpg\n",
            "Writing Copie de frame_2_0024_128_00000000010.jpg\n",
            "Writing Copie de frame_2_0024_129_00000000001.jpg\n",
            "Writing Copie de frame_2_0024_130_11100000000.jpg\n",
            "Writing Copie de frame_2_0024_131_00010000000.jpg\n",
            "Processing: Copie de frame_2_0025.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0025.jpg\n",
            "Processing: Copie de frame_2_0025.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0025.txt\n",
            "Writing Copie de frame_2_0025_132_00001000000.jpg\n",
            "Writing Copie de frame_2_0025_133_00000001000.jpg\n",
            "Writing Copie de frame_2_0025_134_00000000010.jpg\n",
            "Writing Copie de frame_2_0025_135_00000000001.jpg\n",
            "Writing Copie de frame_2_0025_136_11100000000.jpg\n",
            "Writing Copie de frame_2_0025_137_00010000000.jpg\n",
            "Processing: Copie de frame_2_0026.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0026.jpg\n",
            "Processing: Copie de frame_2_0026.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0026.txt\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Bounding Box exception!!!\n",
            "Processing: Copie de frame_2_0027.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0027.jpg\n",
            "Processing: Copie de frame_2_0027.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0027.txt\n",
            "Writing Copie de frame_2_0027_138_00001000000.jpg\n",
            "Writing Copie de frame_2_0027_139_00000001000.jpg\n",
            "Writing Copie de frame_2_0027_140_00000000010.jpg\n",
            "Writing Copie de frame_2_0027_141_00000000001.jpg\n",
            "Writing Copie de frame_2_0027_142_11100000000.jpg\n",
            "Writing Copie de frame_2_0027_143_00010000000.jpg\n",
            "Processing: Copie de frame_2_0028.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0028.jpg\n",
            "Processing: Copie de frame_2_0028.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0028.txt\n",
            "Writing Copie de frame_2_0028_144_00001000000.jpg\n",
            "Writing Copie de frame_2_0028_145_00000001000.jpg\n",
            "Writing Copie de frame_2_0028_146_00000000010.jpg\n",
            "Writing Copie de frame_2_0028_147_00000000001.jpg\n",
            "Writing Copie de frame_2_0028_148_11100000000.jpg\n",
            "Writing Copie de frame_2_0028_149_00010000000.jpg\n",
            "Processing: Copie de frame_2_0029.jpg\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/\n",
            "Copie de frame_2_0029.jpg\n",
            "Processing: Copie de frame_2_0029.txt\n",
            "/content/YOLOBee/Yolov5/frames_04+frames_2/Copie de frame_2_0029.txt\n",
            "Writing Copie de frame_2_0029_150_00001000000.jpg\n",
            "Writing Copie de frame_2_0029_151_00000001000.jpg\n",
            "Writing Copie de frame_2_0029_152_00000000010.jpg\n",
            "Writing Copie de frame_2_0029_153_00000000001.jpg\n",
            "Writing Copie de frame_2_0029_154_11100000000.jpg\n",
            "Writing Copie de frame_2_0029_155_00010000000.jpg\n"
          ]
        }
      ],
      "source": [
        "aug.augment_data(images_path=input_images_folder, image_format=input_image_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "IBptatA9gLBl",
        "outputId": "7902f252-65fa-4152-99f7-a38115c11628"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YOLOBee/Yolov5/train_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.copytree('/content/train_data','YOLOBee/Yolov5/train_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmrIkUjZ-v1z"
      },
      "source": [
        "Training\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To launch the training of the neural network, you need to download the repository yolov5 from ultralytics."
      ],
      "metadata": {
        "id": "jbjP882PRi-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKLa7ME8QiXX",
        "outputId": "a54f6f01-058f-4b41-a1a3-9286888a4819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtrain_data\u001b[0m/  \u001b[01;34mYOLOBee\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VucocSGBjw-U",
        "outputId": "03071e2a-51c4-4e7f-b69e-81e4c9ee2c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOBee/Yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd /content/YOLOBee/Yolov5/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJ53NTz-yXc",
        "outputId": "131da5ce-adcd-46ab-cd43-a97291241142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-334-g100a423b Python-3.10.12 torch-2.3.0+cu121 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.8/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "\n",
        "%pip install -qr /content/YOLOBee/Yolov5/yolov5/requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "\n",
        "from yolov5 import utils\n",
        "\n",
        "%cd yolov5\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything is installed, now the training can began. This is the command line to train the neural network. It uses the pretrained weights of yolov5s and it only training for 50 epoch. If you want the model to be really efficiant you can change the parameters."
      ],
      "metadata": {
        "id": "SiBjTlL7Vda9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgyT4zP3J43Q",
        "outputId": "d4d80b9d-5ba5-4481-b373-10ff651e7ecf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-04 10:23:54.381637: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-04 10:23:54.381719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-04 10:23:54.535604: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../class1.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-334-g100a423b Python-3.10.12 torch-2.3.0+cu121 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 191MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 640\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA not detected, using default CPU batch-size 16\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/YOLOBee/Yolov5/train_data/labels/train... 108 images, 0 backgrounds, 0 corrupt: 100% 108/108 [00:00<00:00, 241.37it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/YOLOBee/Yolov5/train_data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 108/108 [00:04<00:00, 25.42it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLOBee/Yolov5/train_data/labels/val... 48 images, 0 backgrounds, 0 corrupt: 100% 48/48 [00:00<00:00, 225.55it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/YOLOBee/Yolov5/train_data/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 48/48 [00:03<00:00, 15.51it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.76 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4         0G     0.1257    0.03343          0         67        640: 100% 7/7 [03:35<00:00, 30.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:22<00:22, 22.71s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:34<00:00, 17.31s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4         0G     0.1243     0.0321          0         85        640: 100% 7/7 [03:19<00:00, 28.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:23<00:23, 23.36s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:33<00:00, 16.87s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4         0G     0.1162    0.02873          0         93        640: 100% 7/7 [03:26<00:00, 29.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:23<00:23, 23.65s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:34<00:00, 17.18s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4         0G       0.11    0.02718          0         80        640: 100% 7/7 [03:22<00:00, 28.98s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:27<00:27, 27.55s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:39<00:00, 19.76s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4         0G     0.1147    0.02693          0         80        640: 100% 7/7 [03:20<00:00, 28.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:23<00:23, 23.88s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:34<00:00, 17.15s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "\n",
            "5 epochs completed in 0.335 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:22<00:22, 22.64s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:35<00:00, 17.89s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s on Smear images augmented train_data for 500 epochs\n",
        "!python train.py --img 640 --batch -1 --epochs 50 --data ../class1.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8ungS_pGbNE"
      },
      "source": [
        "Validation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training is complete. Now, the validation step will alllow you to see the quality of your training."
      ],
      "metadata": {
        "id": "Gr7ueBA6Wn9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iSK1Ja7GdNT",
        "outputId": "2e49649e-3c43-4adb-8afd-e3d5eb9da7e8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=../class1.yaml, weights=['/content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v7.0-334-g100a423b Python-3.10.12 torch-2.3.0+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLOBee/Yolov5/train_data/labels/val.cache... 48 images, 0 backgrounds, 0 corrupt: 100% 48/48 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:31<00:31, 31.96s/it]WARNING ⚠️ NMS time limit 1.300s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:44<00:00, 22.24s/it]\n",
            "                   all         48        223          0          0          0          0\n",
            "Speed: 7.2ms pre-process, 789.9ms inference, 74.9ms NMS per image at shape (32, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights /content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt --img 640 --data ../class1.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_X4_GDNHbx0"
      },
      "source": [
        "Detection\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation is finished. You can detect bees on pictures or videos"
      ],
      "metadata": {
        "id": "6Fxz2IkbXOW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UDl-4H3gBif",
        "outputId": "dd314a52-31f8-4c00-8744-e149e9dc5d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOBee/Yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.unpack_archive(\"/content/YOLOBee/Yolov5/framesfordetection.zip\")"
      ],
      "metadata": {
        "id": "zdBl0hGPbh6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuL2GQATH-4k",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329c3d89-271f-4204-c9b8-4bb866d3e22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/YOLOBee/Yolov5/detect.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights /content/YOLOBee/Yolov5/yolov5/runs/train/exp/weights/best.pt --img 640 --source '/content/YOLOBee/Yolov5/framesfordetection' --save-txt --save-conf\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
